<html><body><head><style type="text/css">table { border-collapse:collapse; }table td, table thead { border:1px solid black;padding:5px; }table thead {font-weight: bold;}</style></head><body>
<h1>Bluima Components</h1>
<p>This documentation was automatically generated by ch.epfl.bbp.uima.Documentation on 20150220_112036</p>
<h2>Collection Readers</h2><ul>
<li><a href="#ch.epfl.bbp.uima.cr.BioNLPGeniaEventsCollectionReader">BioNLPGeniaEventsCollectionReader</a></li>
<li><a href="#ch.epfl.bbp.uima.cr.Biocreative2GeneCollectionReader">Biocreative2GeneCollectionReader</a></li>
<li><a href="#ch.epfl.bbp.uima.cr.ElsevierReader">ElsevierReader</a></li>
<li><a href="#ch.epfl.bbp.uima.cr.GeniaCorpusCollectionReader">GeniaCorpusCollectionReader</a></li>
<li><a href="#ch.epfl.bbp.uima.cr.NxmlCollectionReader">NxmlCollectionReader</a></li>
<li><a href="#ch.epfl.bbp.uima.cr.PubmedArchiveCollectionReader">PubmedArchiveCollectionReader</a></li>
<li><a href="#ch.epfl.bbp.uima.cr.PubmedArchiveCollectionReader2">PubmedArchiveCollectionReader2</a></li>
<li><a href="#ch.epfl.bbp.uima.cr.PubmedCentralCollectionReader">PubmedCentralCollectionReader</a></li>
<li><a href="#ch.epfl.bbp.uima.cr.UscTteCollectionReader">UscTteCollectionReader</a></li>
<li><a href="#ch.epfl.bbp.uima.cr.WhiteTextCollectionReader">WhiteTextCollectionReader</a></li>
<li><a href="#ch.epfl.bbp.uima.cr.WhiteTextConnectionsCollectionReader">WhiteTextConnectionsCollectionReader</a></li>
<li><a href="#ch.epfl.bbp.uima.cr.XmlTestcaseCollectionReader">XmlTestcaseCollectionReader</a></li>
<li><a href="#ch.epfl.bbp.uima.cr.PubmedDatabaseCR">PubmedDatabaseCR</a></li>
<li><a href="#ch.epfl.bbp.uima.cr.PubmedFromListDatabaseCR">PubmedFromListDatabaseCR</a></li>
<li><a href="#ch.epfl.bbp.uima.cr.PubmedWholeDatabaseCR">PubmedWholeDatabaseCR</a></li>
<li><a href="#ch.epfl.bbp.uima.mongo.BetweenMongoCollectionReader">BetweenMongoCollectionReader</a></li>
<li><a href="#ch.epfl.bbp.uima.mongo.MongoCollectionReader">MongoCollectionReader</a></li>
<li><a href="#ch.epfl.bbp.uima.mongo.MongoCollectionRemover">MongoCollectionRemover</a></li>
<li><a href="#ch.epfl.bbp.uima.mongo.RegexMongoCollectionReader">RegexMongoCollectionReader</a></li>
<li><a href="#ch.epfl.bbp.uima.pdf.cr.PdfCollectionReader">PdfCollectionReader</a></li>
<li><a href="#ch.epfl.bbp.uima.cr.PubmedWebServiceCollectionReader">PubmedWebServiceCollectionReader</a></li>
<li><a href="#ch.epfl.bbp.uima.topicmodels.readers.SingleFileCollectionReader">SingleFileCollectionReader</a></li>
<li><a href="#ch.epfl.bbp.uima.topicmodels.readers.TwentyNewsgroupsCollectionReader">TwentyNewsgroupsCollectionReader</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.serialization.BinaryCasReader">BinaryCasReader</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.serialization.RangeBinaryCasReader">RangeBinaryCasReader</a></li>
<li><a href="#ch.epfl.bbp.uima.cr.AbstractFileReader">AbstractFileReader</a></li>
<li><a href="#ch.epfl.bbp.uima.cr.ConcatReader">ConcatReader</a></li>
<li><a href="#ch.epfl.bbp.uima.cr.FileReader">FileReader</a></li>
<li><a href="#ch.epfl.bbp.uima.cr.FromFilelistReader">FromFilelistReader</a></li>
<li><a href="#ch.epfl.bbp.uima.cr.LdaCReader">LdaCReader</a></li>
<li><a href="#ch.epfl.bbp.uima.cr.OneDocPerLineIdsReader">OneDocPerLineIdsReader</a></li>
<li><a href="#ch.epfl.bbp.uima.cr.OneDocPerLineReader">OneDocPerLineReader</a></li>
<li><a href="#ch.epfl.bbp.uima.cr.OneDocPerLineReader2">OneDocPerLineReader2</a></li>
<li><a href="#ch.epfl.bbp.uima.cr.OneDocPerLineReader3">OneDocPerLineReader3</a></li>
<li><a href="#ch.epfl.bbp.uima.cr.SingleAbstractReader">SingleAbstractReader</a></li>
<li><a href="#ch.epfl.bbp.uima.cr.SingleFileReader">SingleFileReader</a></li>
<li><a href="#ch.epfl.bbp.uima.cr.TextArrayReader">TextArrayReader</a></li>
<li><a href="#ch.epfl.bbp.uima.cr.TextFileReader">TextFileReader</a></li>
<li><a href="#ch.epfl.bbp.uima.cr.TextLineReader">TextLineReader</a></li>
<li><a href="#ch.epfl.bbp.uima.cr.TextReader">TextReader</a></li>
<li><a href="#ch.epfl.bbp.uima.cr.XCollectionReader">XCollectionReader</a></li>
<li><a href="#ch.epfl.bbp.uima.cr.ZipXmiCollectionReader">ZipXmiCollectionReader</a></li>
<li><a href="#ch.epfl.bbp.uima.validation.CrossvalidationReader">CrossvalidationReader</a></li>
</ul>
<h2>Analysis Engines</h2><ul>
<li><a href="#ch.epfl.bbp.uima.ae.AbbreviationsAnnotator">AbbreviationsAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.AbbreviationsConservativeAnnotator">AbbreviationsConservativeAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.AbbreviationsExpanderAnnotator">AbbreviationsExpanderAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.BannerAnnotator">BannerAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.BannerTokenizerAnnotator">BannerTokenizerAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.DragonLemmatiserAnnotator">DragonLemmatiserAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.BamsEvaluateBrainregionsExtraction">BamsEvaluateBrainregionsExtraction</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.BamsEvaluateBrainregionsExtraction2">BamsEvaluateBrainregionsExtraction2</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.EvalTopicDistOnBrAndProts">EvalTopicDistOnBrAndProts</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.EvaluateCoverageAnnotator">EvaluateCoverageAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.ExtractBrainregionsCoocurrences">ExtractBrainregionsCoocurrences</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.ExtractBrainregionsCoocurrences2">ExtractBrainregionsCoocurrences2</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.StudyMorphology">StudyMorphology</a></li>
<li><a href="#ch.epfl.bbp.uima.projects.bluesearch.WriteResultsToFile">WriteResultsToFile</a></li>
<li><a href="#ch.epfl.bbp.uima.projects.preprocessing.PreprocessingStatsAnnotator">PreprocessingStatsAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.projects.preprocessing.PreprocessingStatsAnnotator2">PreprocessingStatsAnnotator2</a></li>
<li><a href="#ch.epfl.bbp.uima.projects.preprocessing.PrintTokensAnnotator">PrintTokensAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.BioAdiAbreviationAnnotator">BioAdiAbreviationAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.BioLemmatizerNormalizerAnnotator">BioLemmatizerNormalizerAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.BlueBioLemmatizer">BlueBioLemmatizer</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.FilterIfNotRodent">FilterIfNotRodent</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.LanguageDetectionAnnotator">LanguageDetectionAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.LinnaeusAnnotator">LinnaeusAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.SpeciesAnnotator">SpeciesAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.SpeciesStats">SpeciesStats</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.WordnetAnnotator">WordnetAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.DatabaseAnnotationWriter">DatabaseAnnotationWriter</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.PubmedDatabaseAE">PubmedDatabaseAE</a></li>
<li><a href="#ch.epfl.bbp.uima.elasticsearch.ElasticIndexer">ElasticIndexer</a></li>
<li><a href="#ch.epfl.bbp.uima.elasticsearch.NeuronIndexer">NeuronIndexer</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.ViterbiFilterAnnotator">ViterbiFilterAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.jsre.JsreFilterAnnotator">JsreFilterAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.jsre.JsreTrainAnnotator">JsreTrainAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.jython.JythonAnnotator">JythonAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.jython.JythonAnnotator2">JythonAnnotator2</a></li>
<li><a href="#ch.epfl.bbp.uima.mongo.MongoUpdateWriter">MongoUpdateWriter</a></li>
<li><a href="#ch.epfl.bbp.uima.mongo.MongoWriter">MongoWriter</a></li>
<li><a href="#ch.epfl.bbp.nlp.neuroner.NeuronWriter">NeuronWriter</a></li>
<li><a href="#ch.epfl.bbp.nlp.neuroner.NeuronWriter2">NeuronWriter2</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.ChunkAnnotator">ChunkAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.PosTagAnnotator">PosTagAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.SentenceAnnotator">SentenceAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.TokenAnnotator">TokenAnnotator</a></li>
<li><a href="#de.julielab.jules.ae.opennlp.ChunkAnnotator">ChunkAnnotator</a></li>
<li><a href="#de.julielab.jules.ae.opennlp.ParseAnnotator">ParseAnnotator</a></li>
<li><a href="#de.julielab.jules.ae.opennlp.PosTagAnnotator">PosTagAnnotator</a></li>
<li><a href="#de.julielab.jules.ae.opennlp.SentenceAnnotator">SentenceAnnotator</a></li>
<li><a href="#de.julielab.jules.ae.opennlp.TokenAnnotator">TokenAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.OscarAnnotator">OscarAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.pdf.cr.PdfCollectionAnnotator">PdfCollectionAnnotator</a></li>
<li><a href="#ch.epfl.bbp.nlp.ie.proteinconc.SectionBasedCoocConfidenceAnnotator">SectionBasedCoocConfidenceAnnotator</a></li>
<li><a href="#ch.epfl.bbp.nlp.ie.proteinconc.ae.AnnotOverlapFilter">AnnotOverlapFilter</a></li>
<li><a href="#ch.epfl.bbp.nlp.ie.proteinconc.ae.BannerMAnnotator">BannerMAnnotator</a></li>
<li><a href="#ch.epfl.bbp.nlp.ie.proteinconc.ae.ChunkAdapter">ChunkAdapter</a></li>
<li><a href="#ch.epfl.bbp.nlp.ie.proteinconc.ae.FigureTitleAnnotator">FigureTitleAnnotator</a></li>
<li><a href="#ch.epfl.bbp.nlp.ie.proteinconc.ae.MoleculeFilter">MoleculeFilter</a></li>
<li><a href="#ch.epfl.bbp.nlp.ie.proteinconc.ae.NormalizedConcentrationAnnotator">NormalizedConcentrationAnnotator</a></li>
<li><a href="#ch.epfl.bbp.nlp.ie.proteinconc.ae.SimpleConcentrationAnnotator">SimpleConcentrationAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.references.PrintStates">PrintStates</a></li>
<li><a href="#ch.epfl.bbp.uima.references.ReferencesClassifierAnnotator">ReferencesClassifierAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.BrainRegionAnnotator">BrainRegionAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.CopyBrainRegionsToDictTerm">CopyBrainRegionsToDictTerm</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.PostprocessRutaEngine">PostprocessRutaEngine</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.BeanshellAnnotator">BeanshellAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.PrintCommentAnnotator">PrintCommentAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.FeatureTokensExtractionAnnotator2">FeatureTokensExtractionAnnotator2</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.TokenFrequencyCounterWriter2">TokenFrequencyCounterWriter2</a></li>
<li><a href="#ch.epfl.bbp.uima.topicmodels.annotators.DCATopicModelsAnnotator">DCATopicModelsAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.topicmodels.annotators.IllegalCharacterSequenceAnnotator">IllegalCharacterSequenceAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.topicmodels.annotators.SimpleStemmingAnnotator">SimpleStemmingAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.topicmodels.annotators.StopwordsAnnotator">StopwordsAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.topicmodels.annotators.TokenFrequencyFilterAnnotator">TokenFrequencyFilterAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.topicmodels.annotators.featureextraction.FeatureTokensExtractionAnnotator">FeatureTokensExtractionAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.topicmodels.annotators.featureextraction.FeatureTokensFilterAnnotator">FeatureTokensFilterAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.topicmodels.writers.JCasWriterConsumer">JCasWriterConsumer</a></li>
<li><a href="#ch.epfl.bbp.uima.topicmodels.writers.TokenFrequencyCounterWriter">TokenFrequencyCounterWriter</a></li>
<li><a href="#ch.epfl.bbp.uima.topicmodels.writers.exploitation.AnnotateTokensWithTopicWriter">AnnotateTokensWithTopicWriter</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.PruneMeasuresAnnotator">PruneMeasuresAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.RT1CellTypeProteinConcentrationExtractor">RT1CellTypeProteinConcentrationExtractor</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.RegExAnnotator">RegExAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.CopyAnnotationsAnnotator">CopyAnnotationsAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.CopyAnnotationsAnnotator2">CopyAnnotationsAnnotator2</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.DeduplicatorAnnotator">DeduplicatorAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.DotSentenceSplitterAnnotator">DotSentenceSplitterAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.EnsureDocHasHeader">EnsureDocHasHeader</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.EnsureDocHasOneSentence">EnsureDocHasOneSentence</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.EnsureDocTextNotNullAnnotator">EnsureDocTextNotNullAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.EnsureTokensHaveLemmaAndPOS">EnsureTokensHaveLemmaAndPOS</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.EntityNormalizerAnnotator">EntityNormalizerAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.EvaluationAnnotator">EvaluationAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.EvaluationPreprocessorAnnotator">EvaluationPreprocessorAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.GarbageCollectorAnnotator">GarbageCollectorAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.GeneralEnglishAnnotator">GeneralEnglishAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.GridSearchConfiguration">GridSearchConfiguration</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.KeepLargestAnnotationAnnotator">KeepLargestAnnotationAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.LucasHelperAnnotator">LucasHelperAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.MultipleProteinsAnnotator">MultipleProteinsAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.NaiveSentenceSplitterAnnotator">NaiveSentenceSplitterAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.NewlineSentenceSplitterAnnotator">NewlineSentenceSplitterAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.PunctuationAnnotator">PunctuationAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.RegexTokenizerAnnotator">RegexTokenizerAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.RemoveAnnotationsAnnotator">RemoveAnnotationsAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.SkipSomePosAnnotator">SkipSomePosAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.SnowballAnnotator">SnowballAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.StaticConfiguration">StaticConfiguration</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.StatsAnnotatorPlus">StatsAnnotatorPlus</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.TestAnnotator">TestAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.WhitespaceTokenizerAnnotator">WhitespaceTokenizerAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.cleanup.SkipSomePosAnnotator2">SkipSomePosAnnotator2</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.cleanup.TooFewTokensFilterAnnotator">TooFewTokensFilterAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.cleanup.TooMuchOOVFilterAnnotator">TooMuchOOVFilterAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.output.AnnotationHistogramAnnotator">AnnotationHistogramAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.output.AnnotationInstanceHistogramAnnotator">AnnotationInstanceHistogramAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.output.AnnotationTypeWriter">AnnotationTypeWriter</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.output.AnnotationTypeWriter2">AnnotationTypeWriter2</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.output.BartWriter">BartWriter</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.output.CountAnnotations">CountAnnotations</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.output.CountAnnotationsAnnotator">CountAnnotationsAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.output.DocumentTextWriter">DocumentTextWriter</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.output.DumpTokensWriter">DumpTokensWriter</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.output.DumpTopics">DumpTopics</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.output.Dumper">Dumper</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.output.HtmlViewerWriter">HtmlViewerWriter</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.output.LdaCWriter">LdaCWriter</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.output.PrintAnnotationInSentenceWriter">PrintAnnotationInSentenceWriter</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.output.SentenceDumpAnnotator">SentenceDumpAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.output.SplitInPages">SplitInPages</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.output.StatsTextAnnotator">StatsTextAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.output.SysoutDumper">SysoutDumper</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.output.XWriter">XWriter</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.output.ZipXWriter">ZipXWriter</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.relations.CooccurrencesEvaluationAnnotator">CooccurrencesEvaluationAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.relations.CooccurrencesEvaluationAnnotator2">CooccurrencesEvaluationAnnotator2</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.relations.ExtractCoocurrences">ExtractCoocurrences</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.relations.ExtractCoocurrencesFilterDistance">ExtractCoocurrencesFilterDistance</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.relations.ExtractSameCoocurrences">ExtractSameCoocurrences</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.relations.FilterCoocurrencesByDistance">FilterCoocurrencesByDistance</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.relations.FilterCoocurrencesByNot">FilterCoocurrencesByNot</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.relations.FilterCoocurrencesByStopwords">FilterCoocurrencesByStopwords</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.relations.FilterCoocurrencesByTriggerword">FilterCoocurrencesByTriggerword</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.relations.FilterCoocurrencesIfTooManyEntities">FilterCoocurrencesIfTooManyEntities</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.relations.FilterCoocurrencesInLongSentences">FilterCoocurrencesInLongSentences</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.relations.FilterInactiveCooccurrencesAnnotator">FilterInactiveCooccurrencesAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.relations.WriteCoocurrencesToLoadfile">WriteCoocurrencesToLoadfile</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.relations.WriteCoocurrencesToLoadfile2">WriteCoocurrencesToLoadfile2</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.relations.WriteCoocurrencesToLoadfile3">WriteCoocurrencesToLoadfile3</a></li>
<li><a href="#ch.epfl.bbp.uima.ae.serialization.BinaryCasWriter">BinaryCasWriter</a></li>
<li><a href="#ch.epfl.bbp.uima.annotationviewer.BlueAnnotationViewerAnnotator">BlueAnnotationViewerAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.filter.AnnotationFilterAnnotator">AnnotationFilterAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.filter.EtAlAnnotator">EtAlAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.filter.FrequencyFilterAnnotator">FrequencyFilterAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.filter.FrequencyFilterWriter">FrequencyFilterWriter</a></li>
<li><a href="#ch.epfl.bbp.uima.filter.KeepsCleaner">KeepsCleaner</a></li>
<li><a href="#ch.epfl.bbp.uima.filter.KeepsDumper">KeepsDumper</a></li>
<li><a href="#ch.epfl.bbp.uima.filter.KeepsWriter">KeepsWriter</a></li>
<li><a href="#ch.epfl.bbp.uima.filter.LeaveOnlyKeepsEnclosedAnnotationsAnnotator">LeaveOnlyKeepsEnclosedAnnotationsAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.filter.MeasureNormalizerAnnotator">MeasureNormalizerAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.filter.PunctuationFilterAnnotator">PunctuationFilterAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.filter.ReferencesFinderAnnotator">ReferencesFinderAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.filter.SectionAnnotator">SectionAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.filter.SectionFilterAnnotator">SectionFilterAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.filter.SectionRegexAnnotator">SectionRegexAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.filter.SentenceFilterAnnotator">SentenceFilterAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.filter.SimpleNormalizerAnnotator">SimpleNormalizerAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.filter.SnowballStemmerNormalizerAnnotator">SnowballStemmerNormalizerAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.filter.StopwordFilterAnnotator">StopwordFilterAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.filter.Tokens2KeepAnnotator">Tokens2KeepAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.filter.TooFewTokensFilterAnnotator">TooFewTokensFilterAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.filter.TooMuchOOVFilterAnnotator">TooMuchOOVFilterAnnotator</a></li>
<li><a href="#ch.epfl.bbp.uima.validation.CrossvalidationWriter">CrossvalidationWriter</a></li>
</ul><hr>
<h3><a id="ch.epfl.bbp.uima.ae.AbbreviationsAnnotator">AbbreviationsAnnotator (ch.epfl.bbp.uima.ae.AbbreviationsAnnotator)</a></h3>
<p>Finds abbreviations in text, using a HMM model from SecondString, trained on biomedical text.<br/> Paper: Alignment-HMM-based extraction of abbreviations from biomedical text (http://dl.acm.org/citation.cfm?id=2391130). We report 98% precision and 93% recall on a standard data set, and 95% precision and 91% recall on an additional test set @see https://github.com/TeamCohen/secondstring</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>retrain</td><td>whether to retrain the model</td><td>Y</td><td>false</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.AbbreviationsAnnotator
 retrain: false
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.AbbreviationsConservativeAnnotator">AbbreviationsConservativeAnnotator (ch.epfl.bbp.uima.ae.AbbreviationsConservativeAnnotator)</a></h3>
<p>Finds abbreviations in text, using a HMM model from SecondString, trained on biomedical text. Compared to AbbreviationsAnnotator, <strong>Only annotates the first occurrence of the abbreviation</strong>. @see https://github.com/TeamCohen/secondstring</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.AbbreviationsConservativeAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.AbbreviationsExpanderAnnotator">AbbreviationsExpanderAnnotator (ch.epfl.bbp.uima.ae.AbbreviationsExpanderAnnotator)</a></h3>
<p>Finds existing Abbreviations and copies into short-forms the annotations from the corresponding long-form. E.g. with "glutamic acid decarboxylase (GAD) is great, i love GAD", if "glutamic acid decarboxylase" get annotated as Protein, the second GAD will get annotated as Protein, too. <strong>Should be run AFTER other NERS</strong> (as it copies the data from them).</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.AbbreviationsExpanderAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.BannerAnnotator">BannerAnnotator (ch.epfl.bbp.uima.ae.BannerAnnotator)</a></h3>
<p>Protein NER that uses BANNER (http://cbioc.eas.asu.edu/banner/). BANNER is a named entity recognition system, primarily intended for biomedical text. It is a machine-learning system based on conditional random fields and contains a wide survey of the best features in recent literature on biomedical named entity recognition (NER). It relies on a CRF model (Mallet). The list of features can be found in CRFTagger  BANNER achieves a F1 of 84.92 on BioCreative2 It is the subject of the following paper: Leaman, R. & Gonzalez G. (2008) BANNER: An executable survey of advances in biomedical named entity recognition. Pacific Symposium on Biocomputing 13:652-663(2008)</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>view</td><td>on which view to process</td><td>Y</td><td>_InitialView</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.BannerAnnotator
 view: _InitialView
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.BannerTokenizerAnnotator">BannerTokenizerAnnotator (ch.epfl.bbp.uima.ae.BannerTokenizerAnnotator)</a></h3>
<p>BANNER's built-in word tokenizer. Tokens ouput by this tokenizer consist of a contiguous block of alphanumeric characters or a single punctuation mark. Note, therefore, that any construction which contains a punctuation mark (such as a contraction or a real number) will necessarily span over at least three tokens.</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.BannerTokenizerAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.DragonLemmatiserAnnotator">DragonLemmatiserAnnotator (ch.epfl.bbp.uima.ae.DragonLemmatiserAnnotator)</a></h3>
<p>Lemmatiser (http://en.wikipedia.org/wiki/Lemmatisation) Annotator that uses the Dragon Toolkit (http://dragon.ischool.drexel.edu/). The Dragon Toolkit is used in BANNER. It is described in the paper Zhou, X., Zhang, X., and Hu, X., "Dragon Toolkit: Incorporating Auto-learned Semantic Knowledge into Large-Scale Text Retrieval and Mining," In proceedings of the 19th IEEE International Conference on Tools with Artificial Intelligence (ICTAI), October 29-31, 2007, Patras, Greece</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>lemmatiser_data</td><td></td><td>Y</td><td>pear_resources/nlpdata/lemmatiser</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.DragonLemmatiserAnnotator
 lemmatiser_data: pear_resources/nlpdata/lemmatiser
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.BamsEvaluateBrainregionsExtraction">BamsEvaluateBrainregionsExtraction (ch.epfl.bbp.uima.ae.BamsEvaluateBrainregionsExtraction)</a></h3>
<p>for BrainRegionDictTerm</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>inputDirectory</td><td></td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.BamsEvaluateBrainregionsExtraction
 inputDirectory: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.BamsEvaluateBrainregionsExtraction2">BamsEvaluateBrainregionsExtraction2 (ch.epfl.bbp.uima.ae.BamsEvaluateBrainregionsExtraction2)</a></h3>
<p>compares BAMS gold against found BR NE (using all NERs, and normalizing using French's Modifiers).</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>inputDirectory</td><td></td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.BamsEvaluateBrainregionsExtraction2
 inputDirectory: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.EvalTopicDistOnBrAndProts">EvalTopicDistOnBrAndProts (ch.epfl.bbp.uima.ae.EvalTopicDistOnBrAndProts)</a></h3>
<p>see 20130729_eval_topic_dist_on_br_and_prots</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.EvalTopicDistOnBrAndProts
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.EvaluateCoverageAnnotator">EvaluateCoverageAnnotator (ch.epfl.bbp.uima.ae.EvaluateCoverageAnnotator)</a></h3>
<p></p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.EvaluateCoverageAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.ExtractBrainregionsCoocurrences">ExtractBrainregionsCoocurrences (ch.epfl.bbp.uima.ae.ExtractBrainregionsCoocurrences)</a></h3>
<p>for BrainRegionDictTerm <code>cd to 20130503_ExtractBrainregionsCoocurrences</code> <code>cd . (if you ran it again...)</code> <code>mysql -uroot</code> <code>use brainregions_relations</code> <code>LOAD DATA LOCAL INFILE 'br_abstract.load_data.txt' INTO TABLE relations FIELDS TERMINATED BY ' ' LINES TERMINATED BY '\n' (`pubmed_id`,`region_1_id`,`region_1_start`,`region_1_end`,`region_2_id`,`region_2_start`,`region_2_end`);</code></p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>outputDir</td><td></td><td>Y</td><td></td></tr>
<tr><td>document_level</td><td>whether to compute coocurrences at the (whole) document level, too</td><td>Y</td><td>false</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.ExtractBrainregionsCoocurrences
 outputDir: <put value here>
 document_level: false
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.ExtractBrainregionsCoocurrences2">ExtractBrainregionsCoocurrences2 (ch.epfl.bbp.uima.ae.ExtractBrainregionsCoocurrences2)</a></h3>
<p>For BrainRegion <code>cd to 20130503_ExtractBrainregionsCoocurrences</code> <code>cd . (if you ran it again...)</code> <code>mysql -uroot</code> <code>use brainregions_relations</code> <code>LOAD DATA LOCAL INFILE 'br_abstract.load_data.txt' INTO TABLE relations FIELDS TERMINATED BY ' ' LINES TERMINATED BY '\n' (`pubmed_id`,`region_1_name`,`region_1_start`,`region_1_end`,`region_2_name`,`region_2_start`,`region_2_end`);</code></p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.ExtractBrainregionsCoocurrences2
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.StudyMorphology">StudyMorphology (ch.epfl.bbp.uima.ae.StudyMorphology)</a></h3>
<p>after extracting BR with NName lex-ner or BrainNER, print each BR token with its POS</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.StudyMorphology
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.projects.bluesearch.WriteResultsToFile">WriteResultsToFile (ch.epfl.bbp.uima.projects.bluesearch.WriteResultsToFile)</a></h3>
<p>brain regions correspond to http://braininfo.rprc.washington.edu/centraldirectory.aspx?ID={the id here}</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>outputDir</td><td></td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.projects.bluesearch.WriteResultsToFile
 outputDir: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.projects.preprocessing.PreprocessingStatsAnnotator">PreprocessingStatsAnnotator (ch.epfl.bbp.uima.projects.preprocessing.PreprocessingStatsAnnotator)</a></h3>
<p>Util to inspect quality of preprocessing, and trace back anomalies back to the original pmid.</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.projects.preprocessing.PreprocessingStatsAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.projects.preprocessing.PreprocessingStatsAnnotator2">PreprocessingStatsAnnotator2 (ch.epfl.bbp.uima.projects.preprocessing.PreprocessingStatsAnnotator2)</a></h3>
<p>Util to inspect quality of preprocessing, and trace back anomalies back to the original <strong>token</strong>.</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.projects.preprocessing.PreprocessingStatsAnnotator2
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.projects.preprocessing.PrintTokensAnnotator">PrintTokensAnnotator (ch.epfl.bbp.uima.projects.preprocessing.PrintTokensAnnotator)</a></h3>
<p>Util to inspect quality of preprocessing, and print tokens</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.projects.preprocessing.PrintTokensAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.BioAdiAbreviationAnnotator">BioAdiAbreviationAnnotator (ch.epfl.bbp.uima.ae.BioAdiAbreviationAnnotator)</a></h3>
<p>Finds abbreviations (e.g. "PC" for pyramidal cells) using BioAdi (http://bioagent.iis.sinica.edu.tw/BIOADI/), Biomedical Abbreviation Definition Identifier. BioAdi identifies the mapping between SF (Short Form) and LF (Long Form) terms in paper. The SF and LF terms can vary and different writing habits generate different subtypes of terms. For example, HCC generally stands for "Hepatocellular Carcinoma", but it can also be written as "Hepatoma", "hepatocellular cancer", "hepato-cellular carcinoma", and so on and so forth. These transformers cause problems on many fields such as database querying, text mining, and literature annotation. Paper: BIOADI: a machine learning approach to identifying abbreviations and definitions in biological literature Cheng-Ju Kuo, Maurice HT Ling, Kuan-Ting Lin, and Chun-Nan Hsu, BMC Bioinformatics. 2009; 10(Suppl 15): S7.</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.BioAdiAbreviationAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.BioLemmatizerNormalizerAnnotator">BioLemmatizerNormalizerAnnotator (ch.epfl.bbp.uima.ae.BioLemmatizerNormalizerAnnotator)</a></h3>
<p>Sets Keep#setNormalizedText() for every Keep annotation to the lemmatization of its covered text. Expects that Token themselves have already been lemmatized (with Token#setLemmaStr())</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>caseSensitive</td><td>If true, tokens are not normalized to lowercase before string comparisions</td><td>Y</td><td>false</td></tr>
<tr><td>onlyTokens</td><td>Only lemmatize the Keeps that are Tokens, rest are left unchanged.</td><td>Y</td><td>false</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.BioLemmatizerNormalizerAnnotator
 caseSensitive: false
 onlyTokens: false
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.BlueBioLemmatizer">BlueBioLemmatizer (ch.epfl.bbp.uima.ae.BlueBioLemmatizer)</a></h3>
<p>This annotator processes tokens in the CAS and inserts corresponding lemmas.</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.BlueBioLemmatizer
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.FilterIfNotRodent">FilterIfNotRodent (ch.epfl.bbp.uima.ae.FilterIfNotRodent)</a></h3>
<p>Removes specific annotation from the CASes if it contains LinnaeusSpecies annotations about Muridae (rats and mices).</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>annotationClass</td><td>The name (including package) of the class to be detagged, use: MyClass.class.getName(), or 'all' to remove ALL annotations</td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.FilterIfNotRodent
 annotationClass: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.LanguageDetectionAnnotator">LanguageDetectionAnnotator (ch.epfl.bbp.uima.ae.LanguageDetectionAnnotator)</a></h3>
<p>Language detection @see http://code.google.com/p/language-detection</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>min_text_length</td><td></td><td>Y</td><td>150</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.LanguageDetectionAnnotator
 min_text_length: 150
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.LinnaeusAnnotator">LinnaeusAnnotator (ch.epfl.bbp.uima.ae.LinnaeusAnnotator)</a></h3>
<p>Linnaeus Uima wrapper, for species name recognition and normalization (http://linnaeus.sourceforge.net/ and http://sourceforge .net/projects/linnaeus/files/Linnaeus/linnaeus-uima-wrapper.pear/download). The provided trained model shows 94% recall and 97% precision on the LINNAEUS-species-corpus. LINNAEUS is the subject of the following paper: Gerner M., Nenadic, G. and Bergman, C. M. (2010) LINNAEUS: a species name identification system for biomedical literature. BMC Bioinformatics 11:85.</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>CONFIG_FILE</td><td></td><td>N</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.LinnaeusAnnotator
 CONFIG_FILE: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.SpeciesAnnotator">SpeciesAnnotator (ch.epfl.bbp.uima.ae.SpeciesAnnotator)</a></h3>
<p>Adds a document-wide DocumentSpecies that is the most prominent species family (see Species enum) of all the LinnaeusSpecies from that document.</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.SpeciesAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.SpeciesStats">SpeciesStats (ch.epfl.bbp.uima.ae.SpeciesStats)</a></h3>
<p></p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.SpeciesStats
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.WordnetAnnotator">WordnetAnnotator (ch.epfl.bbp.uima.ae.WordnetAnnotator)</a></h3>
<p>Wordnet Uima wrapper, using JWI (the MIT Java Wordnet Interface). ATM, find the first match from the lemmatizer. <strong>Needs tokens with POS as input.</strong> @see http://projects.csail.mit.edu/jwi/</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>modelFile</td><td>dict file from Wordnet</td><td>N</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.WordnetAnnotator
 modelFile: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.cr.BioNLPGeniaEventsCollectionReader">BioNLPGeniaEventsCollectionReader (ch.epfl.bbp.uima.cr.BioNLPGeniaEventsCollectionReader)</a></h3>
<p>Corpus reader for the BioNLP 2011 GENIA Event Extraction (GENIA) Shared Task http://2011.bionlp-st.org/home/genia-event-extraction-genia Format: http://www-tsujii.is.s.u-tokyo.ac.jp/GENIA/SharedTask/detail.shtml#format</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>inputDirectory</td><td></td><td>Y</td><td>pear_resources/BioNLP-ST_2011/BioNLP-ST_2011_genia_devel_data_rev1</td></tr>
</table>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.cr.BioNLPGeniaEventsCollectionReader
 inputDirectory: pear_resources/BioNLP-ST_2011/BioNLP-ST_2011_genia_devel_data_rev1
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.cr.Biocreative2GeneCollectionReader">Biocreative2GeneCollectionReader (ch.epfl.bbp.uima.cr.Biocreative2GeneCollectionReader)</a></h3>
<p>CollectionReader for the Biocreative2 (2006) annotated corpus (http://www.biocreative.org/news/biocreative-ii/), containing 20000 sentences from MEDLINE abstracts. P00027739T0000|5 28|gamma glutamyltransferase P00027739T0000|0 28|Serum gamma glutamyltransferase</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>corpus_mode</td><td>mode, either test or train</td><td>Y</td><td>test</td></tr>
<tr><td>corpusRoot</td><td>path to corpus</td><td>Y</td><td>pear_resources/bc2geneMention/</td></tr>
<tr><td>include_alternate</td><td>whether to include the alternate tagged forms</td><td>Y</td><td>true</td></tr>
</table>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.cr.Biocreative2GeneCollectionReader
 corpus_mode: test
 corpusRoot: pear_resources/bc2geneMention/
 include_alternate: true
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.cr.ElsevierReader">ElsevierReader (ch.epfl.bbp.uima.cr.ElsevierReader)</a></h3>
<p>Parsing Elsevier XML for text representation</p>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.cr.ElsevierReader
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.cr.GeniaCorpusCollectionReader">GeniaCorpusCollectionReader (ch.epfl.bbp.uima.cr.GeniaCorpusCollectionReader)</a></h3>
<p>CollectionReader for the GENIA annotated corpus (http://www-tsujii.is.s.u-tokyo.ac.jp/~genia/topics/Corpus/). GENIA Corpus Version 3.0x consists of 2000 abstracts. The base abstracts are selected from the search results with keywords (MeSH terms) Human, Blood Cells, and Transcription Factors.</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>corpusFile</td><td>path to Genia xml corpus</td><td>Y</td><td>pear_resources/GENIAcorpus3.02/GENIAcorpus3.02.xml</td></tr>
</table>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.cr.GeniaCorpusCollectionReader
 corpusFile: pear_resources/GENIAcorpus3.02/GENIAcorpus3.02.xml
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.cr.NxmlCollectionReader">NxmlCollectionReader (ch.epfl.bbp.uima.cr.NxmlCollectionReader)</a></h3>
<p>Collection Reader for nxml files (http://dtd.nlm.nih.gov/).<br/> . Handles most xml tags, but not all yet. Some documents come out empty, as they are of type letter, or book review.</p>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.cr.NxmlCollectionReader
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.cr.PubmedArchiveCollectionReader">PubmedArchiveCollectionReader (ch.epfl.bbp.uima.cr.PubmedArchiveCollectionReader)</a></h3>
<p>Collection Reader for Pubmed Gzipped XML dumps. These can be leased and downloaded from Pubmed (http://www.nlm.nih.gov/databases/journal.html). There are currently ~ 700 dump files. New dumps are added weekly.</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>inputDirectory</td><td></td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.cr.PubmedArchiveCollectionReader
 inputDirectory: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.cr.PubmedArchiveCollectionReader2">PubmedArchiveCollectionReader2 (ch.epfl.bbp.uima.cr.PubmedArchiveCollectionReader2)</a></h3>
<p>Collection Reader for Pubmed Gzipped XML dumps. These can be leased and downloaded from Pubmed (http://www.nlm.nih.gov/databases/journal.html). There are currently ~ 700 dump files. New dumps are added weekly. New file format, I believe</p>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.cr.PubmedArchiveCollectionReader2
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.cr.PubmedCentralCollectionReader">PubmedCentralCollectionReader (ch.epfl.bbp.uima.cr.PubmedCentralCollectionReader)</a></h3>
<p>Collection Reader for Pubmed Central (http://www.ncbi.nlm.nih.gov/pmc/) nxml files (http://dtd.nlm.nih.gov/). The Open Access Subset (http://www.ncbi.nlm.nih.gov/pmc/tools/openftlist/) can be downloaded from PMC's FTP (http://www.ncbi.nlm.nih.gov/pmc/tools/ftp/).</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>inputDirectory</td><td></td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.cr.PubmedCentralCollectionReader
 inputDirectory: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.cr.UscTteCollectionReader">UscTteCollectionReader (ch.epfl.bbp.uima.cr.UscTteCollectionReader)</a></h3>
<p>Collection Reader for the University of Southern California (USC) Tract-tracing experiments (TTE) corpus.</p>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.cr.UscTteCollectionReader
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.cr.WhiteTextCollectionReader">WhiteTextCollectionReader (ch.epfl.bbp.uima.cr.WhiteTextCollectionReader)</a></h3>
<p>Collection Reader for the WhiteText brain regions corpus (http://www.chibi.ubc.ca/WhiteText/). This corpus has 17,585 brain region mentions. Paper: French L, Lane S, Xu L and Pavlidis P (2009) Automated recognition of brain region mentions in neuroscience literature. Front. Neuroinform. 3:29. doi:10.3389/neuro.11.029.2009</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>corpusFile</td><td></td><td>N</td><td></td></tr>
<tr><td>maxNrResults</td><td></td><td>N</td><td>2147483647</td></tr>
</table>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.cr.WhiteTextCollectionReader
 corpusFile: <put value here>
 maxNrResults: 2147483647
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.cr.WhiteTextConnectionsCollectionReader">WhiteTextConnectionsCollectionReader (ch.epfl.bbp.uima.cr.WhiteTextConnectionsCollectionReader)</a></h3>
<p>Collection Reader for the WhiteText CONNECTION brain regions corpus, based on the Airola XML for annotated set. The Airoal XML versions do not contain all of the abstracts, sentences and entities, they only contain sentences with two or more brain region mentions (http://www.chibi.ubc.ca/WhiteText/).  989 docs, 4338 sentences, 13429 brain regions, 3097 co-occurrences  Paper: French L et al. (2012) "Application and evaluation of automated methods to extract neuroanatomical connectivity statements from free text"</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>maxNrResults</td><td></td><td>N</td><td>2147483647</td></tr>
<tr><td>addNegativePairs</td><td>add all possible cooccurrences between the brain regions (true), or just the one that have an interactions (false).</td><td>N</td><td>false</td></tr>
</table>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.cr.WhiteTextConnectionsCollectionReader
 maxNrResults: 2147483647
 addNegativePairs: false
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.cr.XmlTestcaseCollectionReader">XmlTestcaseCollectionReader (ch.epfl.bbp.uima.cr.XmlTestcaseCollectionReader)</a></h3>
<p>Collection Reader for BBP's TestCase XML format. Creates CAS from the XMLs and add the relevant annotations (protein, concentration, celltype). This format is especially relevant for the validation of our first Research Task (see confluence).</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>inputFile</td><td></td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.cr.XmlTestcaseCollectionReader
 inputFile: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.DatabaseAnnotationWriter">DatabaseAnnotationWriter (ch.epfl.bbp.uima.ae.DatabaseAnnotationWriter)</a></h3>
<p>Writes the given Annotations to a specified MySQL database.</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>db_connection</td><td>host, dbname, user, pw</td><td>Y</td><td></td></tr>
<tr><td>createTableStatement</td><td>SQL statement to create the table</td><td>Y</td><td></td></tr>
<tr><td>insertStatement</td><td>SQL statement to insert annotations. The first argument will be (pm)id. Example: INSERT INTO `my_table` (`pmid`, `token`, `begin`, `end`) VALUES (?,?,?,?)</td><td>Y</td><td></td></tr>
<tr><td>annotationClass</td><td>full qualified name of the annotation class. Example: de.julielab.jules.types.Token</td><td>Y</td><td></td></tr>
<tr><td>annotationFields</td><td>ordered array of annotation fields (omitting pmid). Example: { "coveredText", "begin", "end" }</td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.DatabaseAnnotationWriter
 db_connection: <put value here>
 createTableStatement: <put value here>
 insertStatement: <put value here>
 annotationClass: <put value here>
 annotationFields: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.PubmedDatabaseAE">PubmedDatabaseAE (ch.epfl.bbp.uima.ae.PubmedDatabaseAE)</a></h3>
<p>Writes the given JCas to a MySQL database (the bb_pubmed database). Useful for updating it with new articles from PubMed's FTP, for example.</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>db_connection</td><td>host, dbname, user, pw</td><td>Y</td><td>localhost, bb_pubmed, root, </td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.PubmedDatabaseAE
 db_connection: localhost, bb_pubmed, root, 
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.cr.PubmedDatabaseCR">PubmedDatabaseCR (ch.epfl.bbp.uima.cr.PubmedDatabaseCR)</a></h3>
<p>@see PubmedWholeDatabaseCR to iterate the whole Pubmed database</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>between</td><td>specifies a range of pubmed_id, e.g. {13,17} --> 13 <= pubmed_id <= 17. It is recommended to keep it under 1M, as these results are all stored in the db memory</td><td>Y</td><td></td></tr>
<tr><td>skipEmptyDocs</td><td>Skip PubMed articles that have no abstract</td><td>Y</td><td>true</td></tr>
<tr><td>db_connection</td><td>host, dbname, user, pw</td><td>N</td><td>128.178.187.160, bb_pubmed, bemyguest, </td></tr>
<tr><td>expandAbbrevs</td><td>whether to expand Abbreviations</td><td>Y</td><td>false</td></tr>
</table>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.cr.PubmedDatabaseCR
 between: <put value here>
 skipEmptyDocs: true
 db_connection: 128.178.187.160, bb_pubmed, bemyguest, 
 expandAbbrevs: false
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.cr.PubmedFromListDatabaseCR">PubmedFromListDatabaseCR (ch.epfl.bbp.uima.cr.PubmedFromListDatabaseCR)</a></h3>
<p>Allow to read Pubmed articles based on a list of PubMed ids. It is recommended not to use a very large list ( < 100k).</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>db_connection</td><td>host, dbname, user, pw</td><td>N</td><td>128.178.187.160, bb_pubmed, bemyguest, </td></tr>
<tr><td>ids</td><td>a list of pubmed ids</td><td>Y</td><td></td></tr>
<tr><td>expandAbbrevs</td><td>whether to expand Abbreviations</td><td>Y</td><td>false</td></tr>
</table>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.cr.PubmedFromListDatabaseCR
 db_connection: 128.178.187.160, bb_pubmed, bemyguest, 
 ids: <put value here>
 expandAbbrevs: false
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.cr.PubmedWholeDatabaseCR">PubmedWholeDatabaseCR (ch.epfl.bbp.uima.cr.PubmedWholeDatabaseCR)</a></h3>
<p>Allow to iterate the WHOLE db (no BETWEEN)</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>db_connection</td><td>host, dbname, user, pw</td><td>N</td><td>128.178.187.160, bb_pubmed, bemyguest, </td></tr>
<tr><td>skipEmptyDocs</td><td> Skip PubMed articles that have no abstract</td><td>Y</td><td>true</td></tr>
<tr><td>and_query</td><td>specifies an additional query to filter on, e.g.  AND pubmed_id IN (SELECT id FROM neuroscience_ids_from_mesh)</td><td>Y</td><td></td></tr>
<tr><td>expandAbbrevs</td><td>whether to expand Abbreviations</td><td>Y</td><td>false</td></tr>
</table>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.cr.PubmedWholeDatabaseCR
 db_connection: 128.178.187.160, bb_pubmed, bemyguest, 
 skipEmptyDocs: true
 and_query: 
 expandAbbrevs: false
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.elasticsearch.ElasticIndexer">ElasticIndexer (ch.epfl.bbp.uima.elasticsearch.ElasticIndexer)</a></h3>
<p>Indexes every sentences into ElasticSearch, a RESTful search engine server. Also indexes some entities and co-occurrences.</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>host</td><td>the ES host name, use '128.178.187.160' for desktop</td><td>N</td><td>localhost</td></tr>
<tr><td>port</td><td>the ES port name, defaults to 9300</td><td>N</td><td>9300</td></tr>
<tr><td>clusterName</td><td>the ES cluster name</td><td>Y</td><td></td></tr>
<tr><td>indexName</td><td>the ES index name</td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.elasticsearch.ElasticIndexer
 host: localhost
 port: 9300
 clusterName: <put value here>
 indexName: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.elasticsearch.NeuronIndexer">NeuronIndexer (ch.epfl.bbp.uima.elasticsearch.NeuronIndexer)</a></h3>
<p>Indexes every sentences and their corresponding neuron entities into ElasticSearch.</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.elasticsearch.NeuronIndexer
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.ViterbiFilterAnnotator">ViterbiFilterAnnotator (ch.epfl.bbp.uima.ae.ViterbiFilterAnnotator)</a></h3>
<p>Marks annotations that lie on the shortest path to cover a Sentence. Optionally, removes annotations that are not on that shortest path. If multiple annotations pairs are both on the same shortest path node, marks only the "best" one of the annotation pairs (based on confidence). Shortest path is computed using the Viterbi algorithm. Marking is done by adding a Keep annotation.</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>removeOtherAnnotations</td><td>Whether to remove annotations that are not on the shortest path</td><td>Y</td><td>false</td></tr>
<tr><td>removeOverlappingAnnotations</td><td>Whether to remove annotations that are not on the shortest path</td><td>Y</td><td>true</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.ViterbiFilterAnnotator
 removeOtherAnnotations: false
 removeOverlappingAnnotations: true
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.jsre.JsreFilterAnnotator">JsreFilterAnnotator (ch.epfl.bbp.uima.jsre.JsreFilterAnnotator)</a></h3>
<p>Filters Cooccurrences. Uses SLK, see  <i> Claudio Giuliano, Alberto Lavelli, Lorenza Romano. 2006. Exploiting Shallow Linguistic Information for Relation Extraction from Biomedical Literature. </i> and <i>French 2012</i></p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>annotationClass</td><td>the annotation class for the brain region. Can be ch.epfl.bbp.uima.types.BrainRegionDictTerm as well.</td><td>Y</td><td>ch.epfl.bbp.uima.types.BrainRegion</td></tr>
<tr><td>modelFile</td><td>the trained model file</td><td>N</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.jsre.JsreFilterAnnotator
 annotationClass: ch.epfl.bbp.uima.types.BrainRegion
 modelFile: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.jsre.JsreTrainAnnotator">JsreTrainAnnotator (ch.epfl.bbp.uima.jsre.JsreTrainAnnotator)</a></h3>
<p>Trains a SVM to filter Cooccurrences. Uses SLK, see  <i> Claudio Giuliano, Alberto Lavelli, Lorenza Romano. Exploiting Shallow Linguistic Information for Relation Extraction from Biomedical Literature. </i></p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>annotationClass</td><td>the annotation class for the brain region. Can be ch.epfl.bbp.uima.types.BrainRegionDictTerm as well.</td><td>Y</td><td>ch.epfl.bbp.uima.types.BrainRegion</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.jsre.JsreTrainAnnotator
 annotationClass: ch.epfl.bbp.uima.types.BrainRegion
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.jython.JythonAnnotator">JythonAnnotator (ch.epfl.bbp.uima.jython.JythonAnnotator)</a></h3>
<p>Allows Python scripts to be used in UIMA through Jython (http://www.jython.org/)</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>script_path</td><td></td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.jython.JythonAnnotator
 script_path: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.jython.JythonAnnotator2">JythonAnnotator2 (ch.epfl.bbp.uima.jython.JythonAnnotator2)</a></h3>
<p>Allows Python scripts to be used in UIMA through Jython (http://www.jython.org/)</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>script_string</td><td>a String that contains a Python script</td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.jython.JythonAnnotator2
 script_string: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.mongo.BetweenMongoCollectionReader">BetweenMongoCollectionReader (ch.epfl.bbp.uima.mongo.BetweenMongoCollectionReader)</a></h3>
<p>Reads CASes from Mongo, with pmid between certain values</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>between</td><td>specifies a range of pubmed_id, e.g. {13,17} --> 13 <= pubmed_id <= 17</td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.mongo.BetweenMongoCollectionReader
 between: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.mongo.MongoCollectionReader">MongoCollectionReader (ch.epfl.bbp.uima.mongo.MongoCollectionReader)</a></h3>
<p>Reads CASes from Mongo</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>db_connection</td><td>host, dbname, collectionname, user, pw</td><td>Y</td><td></td></tr>
<tr><td>query</td><td>a mongo query, e.g. {my_db_field:{$exists:true}} or {ftr.ns:1} or {pmid: 17} or {pmid:{$in:[12,17]}} or {pmid:{ $gt: 8, $lt: 11 }} </td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.mongo.MongoCollectionReader
 db_connection: <put value here>
 query: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.mongo.MongoCollectionRemover">MongoCollectionRemover (ch.epfl.bbp.uima.mongo.MongoCollectionRemover)</a></h3>
<p>Removes the given annotations from Mongo's CASes. Use it as a collection reader, with no annotator (see MongoCollectionRemover#removeAnnotations()).</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>db_connection</td><td>host, dbname, collectionname, user, pw</td><td>Y</td><td></td></tr>
<tr><td>delete_annotations</td><td></td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.mongo.MongoCollectionRemover
 db_connection: <put value here>
 delete_annotations: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.mongo.MongoUpdateWriter">MongoUpdateWriter (ch.epfl.bbp.uima.mongo.MongoUpdateWriter)</a></h3>
<p>Writes annotations to MongoDB</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>db_connection</td><td>host, dbname, collectionname, user, pw</td><td>Y</td><td></td></tr>
<tr><td>update_all_annotations</td><td>whether to update all annotations found in the cas. Otherwise, specify which annotation to update in 'update_annotations'</td><td>Y</td><td>false</td></tr>
<tr><td>update_annotations</td><td>the specific annotations to update.</td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.mongo.MongoUpdateWriter
 db_connection: <put value here>
 update_all_annotations: false
 update_annotations: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.mongo.MongoWriter">MongoWriter (ch.epfl.bbp.uima.mongo.MongoWriter)</a></h3>
<p>Writes annotations to MongoDB</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>db_connection</td><td>host, dbname, collectionname, user, pw</td><td>Y</td><td></td></tr>
<tr><td>safeMode</td><td>Mongo's WriteConcern SAFE(true) or NORMAL(false)</td><td>Y</td><td>true</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.mongo.MongoWriter
 db_connection: <put value here>
 safeMode: true
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.mongo.RegexMongoCollectionReader">RegexMongoCollectionReader (ch.epfl.bbp.uima.mongo.RegexMongoCollectionReader)</a></h3>
<p>Reads CASes from Mongo, uses a regex to query docs</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>field_name</td><td>the name of the field for the query</td><td>Y</td><td></td></tr>
<tr><td>query</td><td>a regex on that field value</td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.mongo.RegexMongoCollectionReader
 field_name: <put value here>
 query: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.nlp.neuroner.NeuronWriter">NeuronWriter (ch.epfl.bbp.nlp.neuroner.NeuronWriter)</a></h3>
<p>Writes neurons to a file that can be imported in a db.</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>outputFile</td><td>outputfile, or System for sysout</td><td>Y</td><td>out.txt</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.nlp.neuroner.NeuronWriter
 outputFile: out.txt
</pre>
<br/>
<h3><a id="ch.epfl.bbp.nlp.neuroner.NeuronWriter2">NeuronWriter2 (ch.epfl.bbp.nlp.neuroner.NeuronWriter2)</a></h3>
<p>Writes neurons to a file that can be imported in a db. Neuron format: <code>pmId, neuron_id, sentence_id, begin, end, type, text</code></p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>outputFile</td><td>outputfile, or System for sysout</td><td>Y</td><td>out.txt</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.nlp.neuroner.NeuronWriter2
 outputFile: out.txt
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.ChunkAnnotator">ChunkAnnotator (ch.epfl.bbp.uima.ae.ChunkAnnotator)</a></h3>
<p>OpenNLPChunker.java Copyright (c) 2007, JULIE Lab. All rights reserved. This program and the accompanying materials are made available under the terms of the Common Public License v1.0 Author: buyko Current version: 2.0 Since version: 1.0 Creation date: 30.01.2008 OpenNLP Chunker provides chunks to tokens in IOB format (e.g. B-NP, I-VP). This UIMA wrapper provides all needed input parameters to the OpenNLP Chunker and converts the IOB output of the OpenNLP Chunker in CAS.</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>modelFile</td><td></td><td>Y</td><td></td></tr>
<tr><td>posTagSetPreference</td><td>the POS Tagset prefered by this Chunker. If Chunker is trained on
     * PennBioIE, it is recommendable to use PennBioIE POS Tagset</td><td>Y</td><td>de.julielab.jules.types.GeniaPOSTag</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.ChunkAnnotator
 modelFile: 
 posTagSetPreference: de.julielab.jules.types.GeniaPOSTag
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.PosTagAnnotator">PosTagAnnotator (ch.epfl.bbp.uima.ae.PosTagAnnotator)</a></h3>
<p>OpennlpPosTagger.java Copyright (c) 2006, JULIE Lab. All rights reserved. This program and the accompanying materials are made available under the terms of the Common Public License v1.0 Author: buyko Current version: 2.0 Since version: 1.0 Creation date: 30.01.2008 Analysis Engine that invokes the OpenNLP POS Tagger. This annotator assumes that sentences and tokens have been annotated in the CAS. We iterate over sentences, then iterate over tokens in the current sentece to accumulate a list of tokens, then invoke the OpenNLP POS Tagger on the list of tokens.</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>caseSensitive</td><td>Is Tag Dictionary Use Case senstive</td><td>Y</td><td>false</td></tr>
<tr><td>tagset</td><td>the used postagset</td><td>Y</td><td>de.julielab.jules.types.GeniaPOSTag</td></tr>
<tr><td>useTagdict</td><td>true if a tag dictionary should be used, please consider data fields tagdict, caseSensitive</td><td>Y</td><td>true</td></tr>
<tr><td>tagDict</td><td>Path to tag Dictionary</td><td>Y</td><td>pear_resources/models/postag/tagdict-genia</td></tr>
<tr><td>modelFile</td><td></td><td>Y</td><td>pear_resources/models/postag/Tagger_Genia.bin.gz</td></tr>
</table>
<p>Usage (example):</p><pre>@ch.epfl.bbp.uima.ScriptingShortcut(shortcut=ch.epfl.bbp.uima.ae.OpenNlpHelper.getPosTagger())</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.SentenceAnnotator">SentenceAnnotator (ch.epfl.bbp.uima.ae.SentenceAnnotator)</a></h3>
<p>Sentence splitter, based on OpenNLP's MaxEnt SentenceDetector, and trained on biomedical corpora (PennBio or Genia corpora).</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>modelFile</td><td></td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>@ch.epfl.bbp.uima.ScriptingShortcut(shortcut=ch.epfl.bbp.uima.ae.OpenNlpHelper.getSentenceSplitter())</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.TokenAnnotator">TokenAnnotator (ch.epfl.bbp.uima.ae.TokenAnnotator)</a></h3>
<p>OpennlpTokenizer.java Copyright (c) 2006, JULIE Lab. All rights reserved. This program and the accompanying materials are made available under the terms of the Common Public License v1.0 Author: buyko Current version: 2.0	 Since version: 1.0 Creation date: 30.01.2008 Analysis Engine that uses the OpenNLP Tokenizer. This engine assumes that sentences have been annotated in the CAS. It iterates over sentences and invoke the OpenNLP Tokenizer on each sentence.</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>modelFile</td><td></td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>@ch.epfl.bbp.uima.ScriptingShortcut(shortcut=ch.epfl.bbp.uima.ae.OpenNlpHelper.getTokenizer())</pre>
<br/>
<h3><a id="de.julielab.jules.ae.opennlp.ChunkAnnotator">ChunkAnnotator (de.julielab.jules.ae.opennlp.ChunkAnnotator)</a></h3>
<p>OpenNLPChunker.java Copyright (c) 2007, JULIE Lab. All rights reserved. This program and the accompanying materials are made available under the terms of the Common Public License v1.0 Author: buyko Current version: 2.0 Since version: 1.0 Creation date: 30.01.2008 OpenNLP Chunker provides chunks to tokens in IOB format (e.g. B-NP, I-VP). This UIMA wrapper provides all needed input parameters to the OpenNLP Chunker and converts the IOB output of the OpenNLP Chunker in CAS.</p>
<p>Usage (example):</p><pre>ae: de.julielab.jules.ae.opennlp.ChunkAnnotator
</pre>
<br/>
<h3><a id="de.julielab.jules.ae.opennlp.ParseAnnotator">ParseAnnotator (de.julielab.jules.ae.opennlp.ParseAnnotator)</a></h3>
<p>OpenNLPParser.java Copyright (c) 2007, JULIE Lab. All rights reserved. This program and the accompanying materials are made available under the terms of the Common Public License v1.0 Author: buyko Current version: 2.0 Since version: 1.0 Creation date: 30.01.2008 Wrapper for the OpenNLP Parser. Constituency-based parsing.</p>
<p>Usage (example):</p><pre>ae: de.julielab.jules.ae.opennlp.ParseAnnotator
</pre>
<br/>
<h3><a id="de.julielab.jules.ae.opennlp.PosTagAnnotator">PosTagAnnotator (de.julielab.jules.ae.opennlp.PosTagAnnotator)</a></h3>
<p>OpennlpPosTagger.java Copyright (c) 2006, JULIE Lab. All rights reserved. This program and the accompanying materials are made available under the terms of the Common Public License v1.0 Author: buyko Current version: 2.0 Since version: 1.0 Creation date: 30.01.2008 Analysis Engine that invokes the OpenNLP POS Tagger. This annotator assumes that sentences and tokens have been annotated in the CAS. We iterate over sentences, then iterate over tokens in the current sentece to accumulate a list of tokens, then invoke the OpenNLP POS Tagger on the list of tokens.</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>caseSensitive</td><td>Is Tag Dictionary Use Case senstive</td><td>Y</td><td>false</td></tr>
<tr><td>tagset</td><td>the used postagset</td><td>Y</td><td>de.julielab.jules.types.GeniaPOSTag</td></tr>
<tr><td>useTagdict</td><td>true if a tag dictionary should be used, please consider data fields tagdict, caseSensitive</td><td>Y</td><td>true</td></tr>
<tr><td>tagDict</td><td>Path to tag Dictionary</td><td>Y</td><td>pear_resources/models/postag/tagdict-genia</td></tr>
<tr><td>modelFile</td><td></td><td>Y</td><td>pear_resources/models/postag/Tagger_Genia.bin.gz</td></tr>
</table>
<p>Usage (example):</p><pre>ae: de.julielab.jules.ae.opennlp.PosTagAnnotator
 caseSensitive: false
 tagset: de.julielab.jules.types.GeniaPOSTag
 useTagdict: true
 tagDict: pear_resources/models/postag/tagdict-genia
 modelFile: pear_resources/models/postag/Tagger_Genia.bin.gz
</pre>
<br/>
<h3><a id="de.julielab.jules.ae.opennlp.SentenceAnnotator">SentenceAnnotator (de.julielab.jules.ae.opennlp.SentenceAnnotator)</a></h3>
<p>OpennlpSentenceDetector.java Copyright (c) 2006, JULIE Lab. All rights reserved. This program and the accompanying materials are made available under the terms of the Common Public License v1.0 Author: buyko Current version: 2.0 Since version: 1.0 Creation date: 30.01.2008 This wrapper provides the interface to the OpenNLP Sentence Detector @see http://opennlp.sourceforge.net/</p>
<p>Usage (example):</p><pre>ae: de.julielab.jules.ae.opennlp.SentenceAnnotator
</pre>
<br/>
<h3><a id="de.julielab.jules.ae.opennlp.TokenAnnotator">TokenAnnotator (de.julielab.jules.ae.opennlp.TokenAnnotator)</a></h3>
<p>OpennlpTokenizer.java Copyright (c) 2006, JULIE Lab. All rights reserved. This program and the accompanying materials are made available under the terms of the Common Public License v1.0 Author: buyko Current version: 2.0	 Since version: 1.0 Creation date: 30.01.2008 Analysis Engine that uses the OpenNLP Tokenizer. This engine assumes that sentences have been annotated in the CAS. It iterates over sentences and invoke the OpenNLP Tokenizer on each sentence.</p>
<p>Usage (example):</p><pre>ae: de.julielab.jules.ae.opennlp.TokenAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.OscarAnnotator">OscarAnnotator (ch.epfl.bbp.uima.ae.OscarAnnotator)</a></h3>
<p>Wrapper for the OSCAR4 chemical NER, developed by the Murray-Rust research group at the Unilever Centre for Molecular Science Informatics, University of Cambridge (bitbucket.org/wwmm/oscar4/)</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.OscarAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.pdf.cr.PdfCollectionAnnotator">PdfCollectionAnnotator (ch.epfl.bbp.uima.pdf.cr.PdfCollectionAnnotator)</a></h3>
<p>Extracts the text of a PDF file using Snowtide's PDFTextSteam (http://www.snowtide.com/) and optionally the tables found in the PDF using TableSeer (http://sourceforge.net/projects/tableseer/). <br/> This AE is used for local multithreaded processing, and relies on a FileReader to set the file path in the Header</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>extractTables</td><td>whether to extract tables</td><td>Y</td><td>false</td></tr>
<tr><td>expandAbbrevs</td><td>whether to expand Abbreviations</td><td>Y</td><td>false</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.pdf.cr.PdfCollectionAnnotator
 extractTables: false
 expandAbbrevs: false
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.pdf.cr.PdfCollectionReader">PdfCollectionReader (ch.epfl.bbp.uima.pdf.cr.PdfCollectionReader)</a></h3>
<p>Extracts the text of a PDF file using Snowtide's PDFTextSteam (http://www.snowtide.com/) and optionally the tables found in the PDF using TableSeer (http://sourceforge.net/projects/tableseer/). LATER implement Snowtide parser in TableSeer</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>extractTables</td><td>whether to extract tables</td><td>Y</td><td>false</td></tr>
<tr><td>expandAbbrevs</td><td>whether to expand Abbreviations</td><td>Y</td><td>false</td></tr>
<tr><td>extractReferences</td><td>whether to extract references</td><td>Y</td><td>false</td></tr>
</table>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.pdf.cr.PdfCollectionReader
 extractTables: false
 expandAbbrevs: false
 extractReferences: false
</pre>
<br/>
<h3><a id="ch.epfl.bbp.nlp.ie.proteinconc.SectionBasedCoocConfidenceAnnotator">SectionBasedCoocConfidenceAnnotator (ch.epfl.bbp.nlp.ie.proteinconc.SectionBasedCoocConfidenceAnnotator)</a></h3>
<p>Sets the confidence of the co-occurrences according to the following rules: <ul> <li>a co-occurrence appearing in the result section of a paper has a confidence of 1</li> <li>a co-occurrence appearing in the section describing the materials and method has a confidence of -1</li> </ul></p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.nlp.ie.proteinconc.SectionBasedCoocConfidenceAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.nlp.ie.proteinconc.ae.AnnotOverlapFilter">AnnotOverlapFilter (ch.epfl.bbp.nlp.ie.proteinconc.ae.AnnotOverlapFilter)</a></h3>
<p>Removes an annotation when it overlaps with other specified ones. The annotation one want to remove in case of overlapping is called the protected annotation as we protect it against overlapping. The annotations which we do not allow the protected one to overlap with are called the filtered annotations. Note that only instances of the protected annotation will be remove from the index.</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>protectedAnnotationClassName</td><td>the annotation we want to protect against overlaps</td><td>Y</td><td></td></tr>
<tr><td>filteredAnnotationsClassNames</td><td>the forbiden-to-overlap annotations</td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.nlp.ie.proteinconc.ae.AnnotOverlapFilter
 protectedAnnotationClassName: <put value here>
 filteredAnnotationsClassNames: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.nlp.ie.proteinconc.ae.BannerMAnnotator">BannerMAnnotator (ch.epfl.bbp.nlp.ie.proteinconc.ae.BannerMAnnotator)</a></h3>
<p>BannerM is a wrapper for BANNER(1). Allows the user to filter the protein on the length of their name and improves the tokenization of the name of proteins. (1) note that it implies that Banner is not needed below BannerM in the pipeline as BannerM contains BANNER. In addition, including BANNER before BannerM can lead to unpredictable results like two proteins entity mentions overlapping each other.</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>max_length</td><td>the maximum allowed length of a protein (filtering criteria)</td><td>N</td><td>-1</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.nlp.ie.proteinconc.ae.BannerMAnnotator
 max_length: -1
</pre>
<br/>
<h3><a id="ch.epfl.bbp.nlp.ie.proteinconc.ae.ChunkAdapter">ChunkAdapter (ch.epfl.bbp.nlp.ie.proteinconc.ae.ChunkAdapter)</a></h3>
<p>Redefines the Chunk entity appropriately for this project. Namely, it uses chunks annotated by OpenNLP. Then, it cuts those who contains commas in two such that no chunk contains commas. Forces pattern of the form '[protein] ([measure]) to be in the same chunk.</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.nlp.ie.proteinconc.ae.ChunkAdapter
</pre>
<br/>
<h3><a id="ch.epfl.bbp.nlp.ie.proteinconc.ae.FigureTitleAnnotator">FigureTitleAnnotator (ch.epfl.bbp.nlp.ie.proteinconc.ae.FigureTitleAnnotator)</a></h3>
<p>A simple rule-based annotator which detect figure references like 'Fig. 3.2', 'Figure 4.5.3.5', etc.</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.nlp.ie.proteinconc.ae.FigureTitleAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.nlp.ie.proteinconc.ae.MoleculeFilter">MoleculeFilter (ch.epfl.bbp.nlp.ie.proteinconc.ae.MoleculeFilter)</a></h3>
<p>The distinction between proteins and some molecules in BANNER is confusing. That is, the annotator below intend to supress the most frequent molecule annotated as Protein by BANNER.</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.nlp.ie.proteinconc.ae.MoleculeFilter
</pre>
<br/>
<h3><a id="ch.epfl.bbp.nlp.ie.proteinconc.ae.NormalizedConcentrationAnnotator">NormalizedConcentrationAnnotator (ch.epfl.bbp.nlp.ie.proteinconc.ae.NormalizedConcentrationAnnotator)</a></h3>
<p>Annotates the concentration as SimpleConcentrationAnnotator does and normalizes them using the ConcentrationNormalizer.</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.nlp.ie.proteinconc.ae.NormalizedConcentrationAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.nlp.ie.proteinconc.ae.SimpleConcentrationAnnotator">SimpleConcentrationAnnotator (ch.epfl.bbp.nlp.ie.proteinconc.ae.SimpleConcentrationAnnotator)</a></h3>
<p>Annotate annotation using a rule-based approach defined in ConcentrationContext.</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.nlp.ie.proteinconc.ae.SimpleConcentrationAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.cr.PubmedWebServiceCollectionReader">PubmedWebServiceCollectionReader (ch.epfl.bbp.uima.cr.PubmedWebServiceCollectionReader)</a></h3>
<p>CollectionReader that connects to Pubmed's remote search service (webservice API). Allows to query for a specific term (e.g. "cat") or mesh terms (e.g. "brain[mesh]").</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>query</td><td>the query parameter for entrez. E.g. 'cat' or 'brain[mesh]' or '16381840[pmid]' or '17170002 16381840' (for several PMIDs) </td><td>Y</td><td></td></tr>
<tr><td>maxNrResults</td><td>maximum number of results that should be returned</td><td>Y</td><td>100</td></tr>
</table>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.cr.PubmedWebServiceCollectionReader
 query: <put value here>
 maxNrResults: 100
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.references.PrintStates">PrintStates (ch.epfl.bbp.uima.references.PrintStates)</a></h3>
<p>Prints OOOOIOOIIO. For debugging</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.references.PrintStates
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.references.ReferencesClassifierAnnotator">ReferencesClassifierAnnotator (ch.epfl.bbp.uima.references.ReferencesClassifierAnnotator)</a></h3>
<p>Identifies DocumentBlocks that are references (= bibliographical entries), using a MaxEnt classifier (Mallet).</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>model</td><td>the name of the classifier file (not path, just name) </td><td>Y</td><td>references.model</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.references.ReferencesClassifierAnnotator
 model: references.model
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.BrainRegionAnnotator">BrainRegionAnnotator (ch.epfl.bbp.uima.ae.BrainRegionAnnotator)</a></h3>
<p>Annotator NER for brain regions mentions, modeled after <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2741206/">Leon French's NER</a>. Operates in 3 modes: <ul> <li>train: trains a CFR sequence NER based on the provided gold BrainRegion annotations, and writes out a model;</li> <li>infer: annotates JCas with BrainRegions, using a provided model;</li> <li>eval: performs cross validation on an annotated corpus.</li> </ul></p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>mode</td><td>which mode (train, eval, infer)</td><td>N</td><td>infer</td></tr>
<tr><td>threads</td><td>how many threads for eval and train</td><td>N</td><td>3</td></tr>
<tr><td>trials</td><td>cross validation: how many trials</td><td>N</td><td>1</td></tr>
<tr><td>modelFile</td><td>the model file to write to or read from</td><td>N</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.BrainRegionAnnotator
 mode: infer
 threads: 3
 trials: 1
 modelFile: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.CopyBrainRegionsToDictTerm">CopyBrainRegionsToDictTerm (ch.epfl.bbp.uima.ae.CopyBrainRegionsToDictTerm)</a></h3>
<p>Workaround to copy BrainRegion to BrainRegionDictTerm with text</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.CopyBrainRegionsToDictTerm
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.PostprocessRutaEngine">PostprocessRutaEngine (ch.epfl.bbp.uima.ae.PostprocessRutaEngine)</a></h3>
<p>Post-processes the BRCoocs into Cooccurrences.</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.PostprocessRutaEngine
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.BeanshellAnnotator">BeanshellAnnotator (ch.epfl.bbp.uima.ae.BeanshellAnnotator)</a></h3>
<p>Allows BeanShell Java scripts to be used in UIMA. Sets jCas as available variable.</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>script_string</td><td>a String that contains a Beanshell Java script</td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.BeanshellAnnotator
 script_string: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.PrintCommentAnnotator">PrintCommentAnnotator (ch.epfl.bbp.uima.ae.PrintCommentAnnotator)</a></h3>
<p>Lets you print a message to sysout at the end of the pipeline</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>message</td><td>a message to print out</td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.PrintCommentAnnotator
 message: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.FeatureTokensExtractionAnnotator2">FeatureTokensExtractionAnnotator2 (ch.epfl.bbp.uima.ae.FeatureTokensExtractionAnnotator2)</a></h3>
<p>Extract features from the tokens Features extracted from a token are mostly just its string representation or. Some more complex treatments could are implemented, e.g. for measures.</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.FeatureTokensExtractionAnnotator2
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.TokenFrequencyCounterWriter2">TokenFrequencyCounterWriter2 (ch.epfl.bbp.uima.ae.TokenFrequencyCounterWriter2)</a></h3>
<p>Counts the total number of occurrences of ShortestPaths. The counts are maintained in a map. If this map grows large, it is written to a file and a new map is created. The part files have the following format: For each token there is a line, containing the token and its observed count separated by a tab. The lines are sorted in descending order of the tokens. This allows an efficient merging of the files into one. Parameters: the output file path (the part number is appended to the filename) 			 [optional] the maximum number of elements in the map. Default: 1.5 Mio</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.TokenFrequencyCounterWriter2
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.topicmodels.annotators.DCATopicModelsAnnotator">DCATopicModelsAnnotator (ch.epfl.bbp.uima.topicmodels.annotators.DCATopicModelsAnnotator)</a></h3>
<p>Annotates a CAS with LDA topics. Inference of topics based on a previously trained DCA model</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.topicmodels.annotators.DCATopicModelsAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.topicmodels.annotators.IllegalCharacterSequenceAnnotator">IllegalCharacterSequenceAnnotator (ch.epfl.bbp.uima.topicmodels.annotators.IllegalCharacterSequenceAnnotator)</a></h3>
<p>Marks tokens containing illegal character sequences with the Noise annotation Note, that if the character sequences contain whitespaces such as " " or "\t" they are removed by the UIMA framework.</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.topicmodels.annotators.IllegalCharacterSequenceAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.topicmodels.annotators.SimpleStemmingAnnotator">SimpleStemmingAnnotator (ch.epfl.bbp.uima.topicmodels.annotators.SimpleStemmingAnnotator)</a></h3>
<p>Stems all the tokens using the Snowball stemmer The stem is written to the lemma field of the token.</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.topicmodels.annotators.SimpleStemmingAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.topicmodels.annotators.StopwordsAnnotator">StopwordsAnnotator (ch.epfl.bbp.uima.topicmodels.annotators.StopwordsAnnotator)</a></h3>
<p>FIXME remove Marks tokens as stopword, if they appear in the stopwords list.</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.topicmodels.annotators.StopwordsAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.topicmodels.annotators.TokenFrequencyFilterAnnotator">TokenFrequencyFilterAnnotator (ch.epfl.bbp.uima.topicmodels.annotators.TokenFrequencyFilterAnnotator)</a></h3>
<p>Marks tokens as frequent token or hapax.</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.topicmodels.annotators.TokenFrequencyFilterAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.topicmodels.annotators.featureextraction.FeatureTokensExtractionAnnotator">FeatureTokensExtractionAnnotator (ch.epfl.bbp.uima.topicmodels.annotators.featureextraction.FeatureTokensExtractionAnnotator)</a></h3>
<p>Extract features from the tokens Features extracted from a token are mostly just its string representation or. Some more complex treatments could be implemented, e.g. for measures.</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.topicmodels.annotators.featureextraction.FeatureTokensExtractionAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.topicmodels.annotators.featureextraction.FeatureTokensFilterAnnotator">FeatureTokensFilterAnnotator (ch.epfl.bbp.uima.topicmodels.annotators.featureextraction.FeatureTokensFilterAnnotator)</a></h3>
<p>Extract tokens from document which are features, i.e tokens which are annotated as stopwords or some other undesirable category</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.topicmodels.annotators.featureextraction.FeatureTokensFilterAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.topicmodels.readers.SingleFileCollectionReader">SingleFileCollectionReader (ch.epfl.bbp.uima.topicmodels.readers.SingleFileCollectionReader)</a></h3>
<p>UIMA collection reader to read documents stored in a file, one document per line.</p>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.topicmodels.readers.SingleFileCollectionReader
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.topicmodels.readers.TwentyNewsgroupsCollectionReader">TwentyNewsgroupsCollectionReader (ch.epfl.bbp.uima.topicmodels.readers.TwentyNewsgroupsCollectionReader)</a></h3>
<p>Collection reader for the 20 Newsgroups corpus. It is assumed that the documents of each newsgroups are stored seperately in a folder for each newsgroups and that the filenames represent the document id.</p>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.topicmodels.readers.TwentyNewsgroupsCollectionReader
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.topicmodels.writers.JCasWriterConsumer">JCasWriterConsumer (ch.epfl.bbp.uima.topicmodels.writers.JCasWriterConsumer)</a></h3>
<p>Converts features to various formats for LDA softwares</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.topicmodels.writers.JCasWriterConsumer
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.topicmodels.writers.TokenFrequencyCounterWriter">TokenFrequencyCounterWriter (ch.epfl.bbp.uima.topicmodels.writers.TokenFrequencyCounterWriter)</a></h3>
<p>Counts the total number of occurrences of tokens. The counts are maintained in a map. If this map grows large, it is written to a file and a new map is created. The part files have the following format: For each token there is a line, containing the token and its observed count separated by a tab. The lines are sorted in descending order of the tokens. This allows an efficient merging of the files into one. Parameters: the output file path (the part number is appended to the filename) 			 [optional] the maximum number of elements in the map. Default: 1.5 Mio</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.topicmodels.writers.TokenFrequencyCounterWriter
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.topicmodels.writers.exploitation.AnnotateTokensWithTopicWriter">AnnotateTokensWithTopicWriter (ch.epfl.bbp.uima.topicmodels.writers.exploitation.AnnotateTokensWithTopicWriter)</a></h3>
<p>Takes a CAS annotated with topics and generates for each CAS a text file where each token annotated with a topic is printed along with its most likely topic number. The text file can be chosen to be in LaTeX format or plain text.</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.topicmodels.writers.exploitation.AnnotateTokensWithTopicWriter
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.PruneMeasuresAnnotator">PruneMeasuresAnnotator (ch.epfl.bbp.uima.ae.PruneMeasuresAnnotator)</a></h3>
<p>Prunes/dedupes overlapping Measures. Necessary because the RegExAnnotator will create for '128 ± 12 copies' 2 different Measure annotations ('128 ± 12 copies' and '12 copies'), so we need to remove the latter.</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.PruneMeasuresAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.RT1CellTypeProteinConcentrationExtractor">RT1CellTypeProteinConcentrationExtractor (ch.epfl.bbp.uima.ae.RT1CellTypeProteinConcentrationExtractor)</a></h3>
<p>Collects existing annotations (Protein, Concentration and trigger words) and aggregates (copy) them in a CellTypeProteinConcentration.</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.RT1CellTypeProteinConcentrationExtractor
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.RegExAnnotator">RegExAnnotator (ch.epfl.bbp.uima.ae.RegExAnnotator)</a></h3>
<p>Main RegEx annotator implementation class. ren: changed file resolution ren: changed process(), adding ⊂⊃ btw all T</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.RegExAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.CopyAnnotationsAnnotator">CopyAnnotationsAnnotator (ch.epfl.bbp.uima.ae.CopyAnnotationsAnnotator)</a></h3>
<p>Copies specified annotations into other specified annotations, then removes the former.</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>from</td><td>annotation class name to copy</td><td>Y</td><td></td></tr>
<tr><td>to</td><td>annotation class name to copy</td><td>Y</td><td></td></tr>
<tr><td>fromView</td><td>view name to copy from</td><td>N</td><td>_InitialView</td></tr>
<tr><td>toView</td><td>view name to copy from</td><td>N</td><td>_InitialView</td></tr>
<tr><td>deleteFrom</td><td>whether to delete the 'from' annotations (default), or leave them</td><td>Y</td><td>true</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.CopyAnnotationsAnnotator
 from: <put value here>
 to: <put value here>
 fromView: _InitialView
 toView: _InitialView
 deleteFrom: true
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.CopyAnnotationsAnnotator2">CopyAnnotationsAnnotator2 (ch.epfl.bbp.uima.ae.CopyAnnotationsAnnotator2)</a></h3>
<p>Copies specified annotations into other specified annotations, then removes the former.</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>annotationClass</td><td>annotation class name to copy</td><td>Y</td><td></td></tr>
<tr><td>fromView</td><td>view name to copy from</td><td>N</td><td>_InitialView</td></tr>
<tr><td>toView</td><td>view name to copy from</td><td>Y</td><td></td></tr>
<tr><td>deleteFrom</td><td>whether to delete the 'from' annotations (default), or leave them</td><td>Y</td><td>true</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.CopyAnnotationsAnnotator2
 annotationClass: <put value here>
 fromView: _InitialView
 toView: <put value here>
 deleteFrom: true
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.DeduplicatorAnnotator">DeduplicatorAnnotator (ch.epfl.bbp.uima.ae.DeduplicatorAnnotator)</a></h3>
<p>Removes duplicates annotations that have same Class, same begin and same end. TODO: There is no logic yet as how to select the annotation to keep in case of duplicates. @see KeepLargestAnnotationAnnotator for more sophisticated deduplication</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>annotationClasses</td><td>an array with the full name of each annotation classes</td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.DeduplicatorAnnotator
 annotationClasses: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.DotSentenceSplitterAnnotator">DotSentenceSplitterAnnotator (ch.epfl.bbp.uima.ae.DotSentenceSplitterAnnotator)</a></h3>
<p>Splits an input text into Sentences at each dot.</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.DotSentenceSplitterAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.EnsureDocHasHeader">EnsureDocHasHeader (ch.epfl.bbp.uima.ae.EnsureDocHasHeader)</a></h3>
<p>Ensures that all CASes have a Header annotation, sets it to a random value otherwise otherwise.</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.EnsureDocHasHeader
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.EnsureDocHasOneSentence">EnsureDocHasOneSentence (ch.epfl.bbp.uima.ae.EnsureDocHasOneSentence)</a></h3>
<p>Ensures that the jCas has at lease one Sentence annotation, sets it to the whole text otherwise.</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.EnsureDocHasOneSentence
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.EnsureDocTextNotNullAnnotator">EnsureDocTextNotNullAnnotator (ch.epfl.bbp.uima.ae.EnsureDocTextNotNullAnnotator)</a></h3>
<p>Ensures that the text of a CAS is not null, sets it to "" otherwise</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.EnsureDocTextNotNullAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.EnsureTokensHaveLemmaAndPOS">EnsureTokensHaveLemmaAndPOS (ch.epfl.bbp.uima.ae.EnsureTokensHaveLemmaAndPOS)</a></h3>
<p>Checks that each Token has a POS and a lemma, sets otherwise the POS to a "null" string, resp. the lemma to the coveredText itself</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.EnsureTokensHaveLemmaAndPOS
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.EntityNormalizerAnnotator">EntityNormalizerAnnotator (ch.epfl.bbp.uima.ae.EntityNormalizerAnnotator)</a></h3>
<p>Sets Keep#setNormalizedText() for each Keep which encloses an entity (recognized by a ConceptMapper) to the canonical form of the entity.</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.EntityNormalizerAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.EvaluationAnnotator">EvaluationAnnotator (ch.epfl.bbp.uima.ae.EvaluationAnnotator)</a></h3>
<p>Evaluates precision, recall and f-score, comparing annotations in Gold sofa with the annotions in normal view.</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>gold_annotation</td><td>the annotation class name to copy to the gold view (and remove from initial view</td><td>Y</td><td></td></tr>
<tr><td>system_annotation</td><td>the annotation class name to copy to the gold view (and remove from initial view</td><td>Y</td><td></td></tr>
<tr><td>evaluator</td><td>possible values: atLeastCovered, atLeastCovering, exact, overlap</td><td>Y</td><td>exact</td></tr>
<tr><td>verbose</td><td>whether to print verbose logs</td><td>N</td><td>true</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.EvaluationAnnotator
 gold_annotation: <put value here>
 system_annotation: <put value here>
 evaluator: exact
 verbose: true
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.EvaluationPreprocessorAnnotator">EvaluationPreprocessorAnnotator (ch.epfl.bbp.uima.ae.EvaluationPreprocessorAnnotator)</a></h3>
<p>Copies specified annotation to view_gold (later used by EvaluationAnnotator) and removes it from the _InitialView.</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>gold_annotation</td><td>the annotation class name to copy to the gold view (and remove from initial view</td><td>Y</td><td></td></tr>
<tr><td>deleteFrom</td><td>whether to delete the 'from' annotations (default, what you want most of the times), or leave them</td><td>Y</td><td>true</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.EvaluationPreprocessorAnnotator
 gold_annotation: <put value here>
 deleteFrom: true
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.GarbageCollectorAnnotator">GarbageCollectorAnnotator (ch.epfl.bbp.uima.ae.GarbageCollectorAnnotator)</a></h3>
<p>"Forces" to run the garbage collection every N document.</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>runEveryNDocument</td><td></td><td>Y</td><td>10000</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.GarbageCollectorAnnotator
 runEveryNDocument: 10000
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.GeneralEnglishAnnotator">GeneralEnglishAnnotator (ch.epfl.bbp.uima.ae.GeneralEnglishAnnotator)</a></h3>
<p>Annotates general English words. These are loaded from a list file, see http://www.cs.cmu.edu/~chogan/BasicEnglish.html.</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.GeneralEnglishAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.GridSearchConfiguration">GridSearchConfiguration (ch.epfl.bbp.uima.ae.GridSearchConfiguration)</a></h3>
<p><p> Utility/hack to perform in-place (statically configured) parameter configuration for grid-search optimization. NOT INTENDED FOR PROD, BUT WHEN EXPLORING SCENARIOS. <p> Parameters are dynamically loaded, and have to be named "o1", "o2", ... (order is not relevant). They must have the following format: <code>o{1 ...}: paramName{space}paramType{space}value1{space}value2...</code> <p> Examples: <ul> <li><code>o1: test1 bool</code></li> <li><code>o2: test2 int 1 3 5</code></li> <li><code>o2: test3 string a b asdf</code></li> </ul> Then, you can specify which combinaison to use with StaticConfiguration#COMBINAISON_INDEX</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>combinaisonIndex</td><td>The index of the current option</td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.GridSearchConfiguration
 combinaisonIndex: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.KeepLargestAnnotationAnnotator">KeepLargestAnnotationAnnotator (ch.epfl.bbp.uima.ae.KeepLargestAnnotationAnnotator)</a></h3>
<p>Prunes/dedupes overlapping Annotations, keeps the largest one. @see DeduplicatorAnnotator for simpler algo @see ViterbiAnnotator for complex tasks and multiple annotation types</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>annotationClass</td><td>the full name of the annotation class</td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.KeepLargestAnnotationAnnotator
 annotationClass: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.LucasHelperAnnotator">LucasHelperAnnotator (ch.epfl.bbp.uima.ae.LucasHelperAnnotator)</a></h3>
<p>Adds e.g. setAnnotType("⊂AGE⊃") to all AgeDictTerm annotations. This is used by Lucas</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.LucasHelperAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.MultipleProteinsAnnotator">MultipleProteinsAnnotator (ch.epfl.bbp.uima.ae.MultipleProteinsAnnotator)</a></h3>
<p>Adds a MultipleProteins annotations if there is more that one Protein in this document</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.MultipleProteinsAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.NaiveSentenceSplitterAnnotator">NaiveSentenceSplitterAnnotator (ch.epfl.bbp.uima.ae.NaiveSentenceSplitterAnnotator)</a></h3>
<p>Sentence splitter that outputs the content of the whole CAS text as one single Sentence. Mostly useful for testing. Othewise, see OpenNLP module.</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.NaiveSentenceSplitterAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.NewlineSentenceSplitterAnnotator">NewlineSentenceSplitterAnnotator (ch.epfl.bbp.uima.ae.NewlineSentenceSplitterAnnotator)</a></h3>
<p>Splits an input text into Sentences at each new line.</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.NewlineSentenceSplitterAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.PunctuationAnnotator">PunctuationAnnotator (ch.epfl.bbp.uima.ae.PunctuationAnnotator)</a></h3>
<p>Annotates Tokens consisting (exclusively) of punctuation chars. Extensive (agressive) matching (see PunctuationAnnotator#PUNCT) @input Punctuation</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.PunctuationAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.RegexTokenizerAnnotator">RegexTokenizerAnnotator (ch.epfl.bbp.uima.ae.RegexTokenizerAnnotator)</a></h3>
<p>Tokenizer that can be configured with a regex Pattern. Mostly useful for tests.</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>tokenizationPattern</td><td>a String that will be compiled to a regex Pattern, and used for tokenization</td><td>Y</td><td>(?<=[(a-zA-Z_0-9\-)])(?=[^(a-zA-Z_0-9\-)])|(?<=[^(a-zA-Z_0-9\-)])(?=[(a-zA-Z_0-9\-)])</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.RegexTokenizerAnnotator
 tokenizationPattern: (?<=[(a-zA-Z_0-9\-)])(?=[^(a-zA-Z_0-9\-)])|(?<=[^(a-zA-Z_0-9\-)])(?=[(a-zA-Z_0-9\-)])
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.RemoveAnnotationsAnnotator">RemoveAnnotationsAnnotator (ch.epfl.bbp.uima.ae.RemoveAnnotationsAnnotator)</a></h3>
<p>Removes specific annotation from the CASes</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>annotationClass</td><td>The name (including package) of the class to be detagged, use: MyClass.class.getName(), or 'all' to remove ALL annotations</td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.RemoveAnnotationsAnnotator
 annotationClass: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.SkipSomePosAnnotator">SkipSomePosAnnotator (ch.epfl.bbp.uima.ae.SkipSomePosAnnotator)</a></h3>
<p>Annotate (flags) tokens that have an "uninteresting" POS, like V.., W.., DT or TO, IN, ...</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.SkipSomePosAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.SnowballAnnotator">SnowballAnnotator (ch.epfl.bbp.uima.ae.SnowballAnnotator)</a></h3>
<p>Snowball stemmer annotator for Tokens</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.SnowballAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.StaticConfiguration">StaticConfiguration (ch.epfl.bbp.uima.ae.StaticConfiguration)</a></h3>
<p>Utility to perform in-place (statically configured) parameter configuration for optimization. Parameters are set like this: <code>paramName{space}paramType{space}value1{space}value2...</code> Examples: <ul> <li><code>o1: myparam1 bool true</code></li> <li><code>o2: myparam2 int 3</code></li> <li><code>o3: myparam2 dble 3.14</code></li> <li><code>o4: myparam3 string asdf</code></li> </ul>  Then, in your java code you can retreive the vales using the StaticOption.getXXX methods</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.StaticConfiguration
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.StatsAnnotatorPlus">StatsAnnotatorPlus (ch.epfl.bbp.uima.ae.StatsAnnotatorPlus)</a></h3>
<p>Logs statistics about the progress of the pipeline to the console.</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>printEvery</td><td>print every n doc</td><td>Y</td><td>1000</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.StatsAnnotatorPlus
 printEvery: 1000
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.TestAnnotator">TestAnnotator (ch.epfl.bbp.uima.ae.TestAnnotator)</a></h3>
<p>Tests the number of annotations on each CAS. Probably only useful when testing a pipeline that processes a few documents.</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>expects</td><td>pour le premier document: [{annot} {expected_count}, ]* , e.g. de.julielab.jules.types.Token 10, ch.epfl.bbp.uima.types.GeneralEnglish 4</td><td>Y</td><td></td></tr>
<tr><td>expects2</td><td>pour le second document: [{annot} {expected_count}, ]* , e.g. de.julielab.jules.types.Token 10, ch.epfl.bbp.uima.types.GeneralEnglish 4</td><td>N</td><td></td></tr>
<tr><td>expects3</td><td>pour le 3eme document: [{annot} {expected_count}, ]* , e.g. de.julielab.jules.types.Token 10, ch.epfl.bbp.uima.types.GeneralEnglish 4</td><td>N</td><td></td></tr>
<tr><td>expects4</td><td>pour le 4eme document: [{annot} {expected_count}, ]* , e.g. de.julielab.jules.types.Token 10, ch.epfl.bbp.uima.types.GeneralEnglish 4</td><td>N</td><td></td></tr>
<tr><td>expects5</td><td>pour le 5eme document: [{annot} {expected_count}, ]* , e.g. de.julielab.jules.types.Token 10, ch.epfl.bbp.uima.types.GeneralEnglish 4</td><td>N</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.TestAnnotator
 expects: <put value here>
 expects2: <put value here>
 expects3: <put value here>
 expects4: <put value here>
 expects5: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.WhitespaceTokenizerAnnotator">WhitespaceTokenizerAnnotator (ch.epfl.bbp.uima.ae.WhitespaceTokenizerAnnotator)</a></h3>
<p>Simple whitespace tokenizer. Useful mostly for tests.</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.WhitespaceTokenizerAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.cleanup.SkipSomePosAnnotator2">SkipSomePosAnnotator2 (ch.epfl.bbp.uima.ae.cleanup.SkipSomePosAnnotator2)</a></h3>
<p>Bluntly removes annotations that cover a word with an uninteresting POS, like DT or TO, IN, ...</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.cleanup.SkipSomePosAnnotator2
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.cleanup.TooFewTokensFilterAnnotator">TooFewTokensFilterAnnotator (ch.epfl.bbp.uima.ae.cleanup.TooFewTokensFilterAnnotator)</a></h3>
<p>Flags a document that has too few tokens per page (< 50 on average)</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.cleanup.TooFewTokensFilterAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.cleanup.TooMuchOOVFilterAnnotator">TooMuchOOVFilterAnnotator (ch.epfl.bbp.uima.ae.cleanup.TooMuchOOVFilterAnnotator)</a></h3>
<p>Flags a document that has too much OOV tokens, compared to a frequency list.</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.cleanup.TooMuchOOVFilterAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.output.AnnotationHistogramAnnotator">AnnotationHistogramAnnotator (ch.epfl.bbp.uima.ae.output.AnnotationHistogramAnnotator)</a></h3>
<p>Prints a histogram of the counts of each and every Annotation in the JCas. E.g. <pre> ch.epfl.bbp.uima.types.BrainRegionDictTerm: 123 ch.epfl.bbp.uima.types.Sex: 4312 ch.epfl.bbp.uima.types.Rocknroll: 412 </pre></p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>printForEveryCas</td><td></td><td>Y</td><td>false</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.output.AnnotationHistogramAnnotator
 printForEveryCas: false
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.output.AnnotationInstanceHistogramAnnotator">AnnotationInstanceHistogramAnnotator (ch.epfl.bbp.uima.ae.output.AnnotationInstanceHistogramAnnotator)</a></h3>
<p>At the end of the whole pipeline, prints a histogram (counts) of all instances of a given Annotation. E.g. <pre> hello: 123 world: 4312 </pre></p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>annotationClass</td><td>annotation class name to count</td><td>Y</td><td></td></tr>
<tr><td>annotationField</td><td>The name of the annotation field to get the title from.</td><td>N</td><td>coveredText</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.output.AnnotationInstanceHistogramAnnotator
 annotationClass: <put value here>
 annotationField: coveredText
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.output.AnnotationTypeWriter">AnnotationTypeWriter (ch.epfl.bbp.uima.ae.output.AnnotationTypeWriter)</a></h3>
<p>A consumer that writes out specified Annotations and features to a specified text file</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>outputFile</td><td>outputfile, or System for sysout</td><td>Y</td><td>out.txt</td></tr>
<tr><td>annotationClass</td><td>the full name of the annotation class</td><td>Y</td><td>org.apache.uima.jcas.tcas.Annotation</td></tr>
<tr><td>featureName</td><td>the name of the feature to extract, or none for the text only</td><td>N</td><td></td></tr>
<tr><td>filterFeaturesWithValue</td><td>filter the features that have this value</td><td>N</td><td></td></tr>
<tr><td>param_new_line</td><td>whether to add a new line after each token</td><td>N</td><td>true</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.output.AnnotationTypeWriter
 outputFile: out.txt
 annotationClass: org.apache.uima.jcas.tcas.Annotation
 featureName: <put value here>
 filterFeaturesWithValue: <put value here>
 param_new_line: true
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.output.AnnotationTypeWriter2">AnnotationTypeWriter2 (ch.epfl.bbp.uima.ae.output.AnnotationTypeWriter2)</a></h3>
<p>A consumer that writes out specified Annotations and features to a specified text file, prepending each line with pmId and begin-end. Example: <pre> 123 0 5 hello 123 6 11 brave 123 12 17 world </pre></p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.output.AnnotationTypeWriter2
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.output.BartWriter">BartWriter (ch.epfl.bbp.uima.ae.output.BartWriter)</a></h3>
<p>A consumer that writes out specified Annotations into static files, for BRAT's stand-off format (http://brat.nlplab.org/standoff.html)</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>addBratFiles</td><td>whether to add the complete, working brat server</td><td>Y</td><td>true</td></tr>
<tr><td>batchPrefix</td><td>prefix to add for each file in Brat; useful when comparing different batches</td><td>Y</td><td></td></tr>
<tr><td>debug</td><td>prints out annotations to StdOut</td><td>Y</td><td>false</td></tr>
<tr><td>notes</td><td>write notes (for hover)</td><td>Y</td><td>false</td></tr>
<tr><td>splitPerPage</td><td>splits out Bart output per page</td><td>Y</td><td>false</td></tr>
<tr><td>outputDir</td><td></td><td>N</td><td>brat</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.output.BartWriter
 addBratFiles: true
 batchPrefix: 
 debug: false
 notes: false
 splitPerPage: false
 outputDir: brat
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.output.CountAnnotations">CountAnnotations (ch.epfl.bbp.uima.ae.output.CountAnnotations)</a></h3>
<p>Count specified annotationS, write</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>outputFile</td><td></td><td>Y</td><td></td></tr>
<tr><td>annotationClasses</td><td>annotation classes name to count</td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.output.CountAnnotations
 outputFile: <put value here>
 annotationClasses: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.output.CountAnnotationsAnnotator">CountAnnotationsAnnotator (ch.epfl.bbp.uima.ae.output.CountAnnotationsAnnotator)</a></h3>
<p>At the end of the whole pipeline, prints the count of occurrences of some specified annotations @see AnnotationHistogramAnnotator @see AnnotationInstanceHistogramAnnotator</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>annotationClass</td><td>annotation class name to count</td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.output.CountAnnotationsAnnotator
 annotationClass: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.output.DocumentTextWriter">DocumentTextWriter (ch.epfl.bbp.uima.ae.output.DocumentTextWriter)</a></h3>
<p>Dumps the document text to a text file</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>outputDir</td><td></td><td>Y</td><td>target/docs</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.output.DocumentTextWriter
 outputDir: target/docs
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.output.DumpTokensWriter">DumpTokensWriter (ch.epfl.bbp.uima.ae.output.DumpTokensWriter)</a></h3>
<p>A consumer that writes out Tokens to a text file (one file per JCas)</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>outputDir</td><td></td><td>Y</td><td>output</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.output.DumpTokensWriter
 outputDir: output
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.output.DumpTopics">DumpTopics (ch.epfl.bbp.uima.ae.output.DumpTopics)</a></h3>
<p>Dumps TopicDistribution to sysout</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.output.DumpTopics
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.output.Dumper">Dumper (ch.epfl.bbp.uima.ae.output.Dumper)</a></h3>
<p>Dumps it all to sysout</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.output.Dumper
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.output.HtmlViewerWriter">HtmlViewerWriter (ch.epfl.bbp.uima.ae.output.HtmlViewerWriter)</a></h3>
<p>T\d+\t([A-Z]{3,111}|Token|CW)</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>outputDir</td><td>output directory , defaults to target/htmlViewer</td><td>Y</td><td>target/htmlViewer/</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.output.HtmlViewerWriter
 outputDir: target/htmlViewer/
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.output.LdaCWriter">LdaCWriter (ch.epfl.bbp.uima.ae.output.LdaCWriter)</a></h3>
<p>Output Keeps into the LDA-C format: <code> [M] [term_1]:[count] [term_2]:[count] ... [term_N]:[count]</code> where [M] is the number of unique terms in the document, and the [count] associated with each term is how many times that term appeared in the document. Also writes the corresponding vocabulary file, one Keep per line. The writer can be used separately: <pre> writer = new LdaCWriter.Writer(&quot; &quot;, corpusFile, vocabFile); writer.addDocument(wordList); writer.close(); </pre></p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>outputFile</td><td></td><td>Y</td><td></td></tr>
<tr><td>vocabularyOutputFile</td><td></td><td>N</td><td></td></tr>
<tr><td>vocabularyInputFile</td><td></td><td>N</td><td></td></tr>
<tr><td>idsOutputFile</td><td>(optional) outputs a list of pmids alongside</td><td>N</td><td></td></tr>
<tr><td>dcaFormat</td><td>wheter to output in DCA format (without ':')</td><td>Y</td><td>false</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.output.LdaCWriter
 outputFile: <put value here>
 vocabularyOutputFile: <put value here>
 vocabularyInputFile: <put value here>
 idsOutputFile: <put value here>
 dcaFormat: false
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.output.PrintAnnotationInSentenceWriter">PrintAnnotationInSentenceWriter (ch.epfl.bbp.uima.ae.output.PrintAnnotationInSentenceWriter)</a></h3>
<p>Writes out specified Annotations and its enclosing sentence to a specified text file</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>outputFile</td><td>outputfile, or null for sysout</td><td>N</td><td></td></tr>
<tr><td>annotationClass</td><td>the full name of the annotation class</td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.output.PrintAnnotationInSentenceWriter
 outputFile: <put value here>
 annotationClass: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.output.SentenceDumpAnnotator">SentenceDumpAnnotator (ch.epfl.bbp.uima.ae.output.SentenceDumpAnnotator)</a></h3>
<p>Format is: <code>pmId:sentId{tab}text</code> @see OneDocPerLineReader</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>outputFile</td><td>A path to the output file</td><td>Y</td><td>sentences.txt</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.output.SentenceDumpAnnotator
 outputFile: sentences.txt
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.output.SplitInPages">SplitInPages (ch.epfl.bbp.uima.ae.output.SplitInPages)</a></h3>
<p>Add a DocumentPage annotation every X Sentence</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.output.SplitInPages
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.output.StatsTextAnnotator">StatsTextAnnotator (ch.epfl.bbp.uima.ae.output.StatsTextAnnotator)</a></h3>
<p>Statistics (histogram) of document text length. Bins are rounded to 100</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.output.StatsTextAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.output.SysoutDumper">SysoutDumper (ch.epfl.bbp.uima.ae.output.SysoutDumper)</a></h3>
<p>Dumps document text to sysout</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.output.SysoutDumper
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.output.XWriter">XWriter (ch.epfl.bbp.uima.ae.output.XWriter)</a></h3>
<p>A simple CAS consumer that generates XCAS (XML representation of the CAS) files in the filesystem. renaud: Removing createConfigurationParameterName</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>outputDir</td><td>takes a path to directory into which output files will be written.</td><td>Y</td><td></td></tr>
<tr><td>xmlSchemeName</td><td>specifies the UIMA XML serialization scheme that should be used. Valid values for this parameter are 'XMI' (default) and 'XCAS'.</td><td>Y</td><td>XMI</td></tr>
<tr><td>fileNamerClassName</td><td>the class name of the XWriterFileNamer implementation to use</td><td>Y</td><td>org.apache.uima.fit.component.xwriter.IntegerFileNamer</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.output.XWriter
 outputDir: <put value here>
 xmlSchemeName: XMI
 fileNamerClassName: org.apache.uima.fit.component.xwriter.IntegerFileNamer
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.output.ZipXWriter">ZipXWriter (ch.epfl.bbp.uima.ae.output.ZipXWriter)</a></h3>
<p>A simple CAS consumer that generates zipped XCAS (XML representation of the CAS) files in the filesystem.</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>outputDir</td><td>takes a path to directory into which output files will be written.</td><td>Y</td><td></td></tr>
<tr><td>org.apache.uima.fit.descriptor.ConfigurationParameter.USE_FIELD_NAME</td><td>specifies the UIMA XML serialization scheme that should be used. Valid values for this parameter are 'XMI' (default) and 'XCAS'.</td><td>Y</td><td>XMI</td></tr>
<tr><td>org.apache.uima.fit.descriptor.ConfigurationParameter.USE_FIELD_NAME</td><td>the class name of the XWriterFileNamer implementation to use</td><td>Y</td><td>org.apache.uima.fit.component.xwriter.IntegerFileNamer</td></tr>
<tr><td>org.apache.uima.fit.descriptor.ConfigurationParameter.USE_FIELD_NAME</td><td>whether to output in a structure directory</td><td>N</td><td>false</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.output.ZipXWriter
 outputDir: <put value here>
 org.apache.uima.fit.descriptor.ConfigurationParameter.USE_FIELD_NAME: XMI
 org.apache.uima.fit.descriptor.ConfigurationParameter.USE_FIELD_NAME: org.apache.uima.fit.component.xwriter.IntegerFileNamer
 org.apache.uima.fit.descriptor.ConfigurationParameter.USE_FIELD_NAME: false
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.relations.CooccurrencesEvaluationAnnotator">CooccurrencesEvaluationAnnotator (ch.epfl.bbp.uima.ae.relations.CooccurrencesEvaluationAnnotator)</a></h3>
<p>Evaluates if two Cooccurrence's entities are the same. Any entities can be used, since they are compared on start/end of them. @see EvaluationAnnotator</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.relations.CooccurrencesEvaluationAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.relations.CooccurrencesEvaluationAnnotator2">CooccurrencesEvaluationAnnotator2 (ch.epfl.bbp.uima.ae.relations.CooccurrencesEvaluationAnnotator2)</a></h3>
<p>Evaluates Cooccurrences for projects/extract_brainregions/20140221_slurm_extraction  In particular, evaluates permutations of the 3 extractors @see EvaluationAnnotator</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>extractorSetup</td><td>e.g. 0 0 1, or best</td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.relations.CooccurrencesEvaluationAnnotator2
 extractorSetup: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.relations.ExtractCoocurrences">ExtractCoocurrences (ch.epfl.bbp.uima.ae.relations.ExtractCoocurrences)</a></h3>
<p>Extracts cooccurrences @see WriteCoocurrencesToLoadfile WriteCoocurrencesToLoadfile to write these  cooccurrences to a file</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>enclosingScope</td><td>the enclosing scope to iterate on and extract co-occurrence from. Defaults to sentences</td><td>N</td><td>de.julielab.jules.types.Sentence</td></tr>
<tr><td>annot1</td><td>the first annotation to extract co-occurrences from</td><td>Y</td><td></td></tr>
<tr><td>annot1IdField</td><td>The name of the annotation field to get the entity id from. Uses coveredText as default to get the text of the annotation itself.Note that one can add multiple fields separated by commas.</td><td>Y</td><td>coveredText</td></tr>
<tr><td>annot2</td><td>the first annotation to extract co-occurrences from</td><td>Y</td><td></td></tr>
<tr><td>annot2IdField</td><td>the name of the annotation field to get the entity id from. Uses coveredText as default to get the text of the annotation itself.Note that one can add multiple fields separated by commas.</td><td>Y</td><td>coveredText</td></tr>
<tr><td>cooccurrenceType</td><td>A string to distinguish the co-occurrence.</td><td>Y</td><td></td></tr>
<tr><td>keepOnlyNearestNeighbors</td><td>keep only one co-occurrence per entity based on the distance between the two elements of the co-occurrence</td><td>Y</td><td>false</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.relations.ExtractCoocurrences
 enclosingScope: de.julielab.jules.types.Sentence
 annot1: <put value here>
 annot1IdField: coveredText
 annot2: <put value here>
 annot2IdField: coveredText
 cooccurrenceType: 
 keepOnlyNearestNeighbors: false
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.relations.ExtractCoocurrencesFilterDistance">ExtractCoocurrencesFilterDistance (ch.epfl.bbp.uima.ae.relations.ExtractCoocurrencesFilterDistance)</a></h3>
<p>Extracts cooccurrences, filtering by maximum distance. <strong> Use FilterCoocurrencesByDistance instead.</strong></p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>maximumDistance</td><td>TODO</td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.relations.ExtractCoocurrencesFilterDistance
 maximumDistance: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.relations.ExtractSameCoocurrences">ExtractSameCoocurrences (ch.epfl.bbp.uima.ae.relations.ExtractSameCoocurrences)</a></h3>
<p>Extracts cooccurrences of the same Annotation class. @see WriteCoocurrencesToLoadfile WriteCoocurrencesToLoadfile to write these  cooccurrences to a file</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.relations.ExtractSameCoocurrences
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.relations.FilterCoocurrencesByDistance">FilterCoocurrencesByDistance (ch.epfl.bbp.uima.ae.relations.FilterCoocurrencesByDistance)</a></h3>
<p>Filters cooccurrences whose two entities are separated by more that the specified distance. Improves precision at the cost of recall.</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>maximumDistance</td><td>the maximum distance between the 2 entities of that co-occurrence</td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.relations.FilterCoocurrencesByDistance
 maximumDistance: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.relations.FilterCoocurrencesByNot">FilterCoocurrencesByNot (ch.epfl.bbp.uima.ae.relations.FilterCoocurrencesByNot)</a></h3>
<p>Filters cooccurrences whose sentence contains `not?`. Improves precision at the cost of recall.</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.relations.FilterCoocurrencesByNot
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.relations.FilterCoocurrencesByStopwords">FilterCoocurrencesByStopwords (ch.epfl.bbp.uima.ae.relations.FilterCoocurrencesByStopwords)</a></h3>
<p>Filters cooccurrences whose sentence contains stopwords, e.g. sentences starting with 'Abbreviations:'. Improves precision at the cost of recall. NOTE: does not perform well</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.relations.FilterCoocurrencesByStopwords
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.relations.FilterCoocurrencesByTriggerword">FilterCoocurrencesByTriggerword (ch.epfl.bbp.uima.ae.relations.FilterCoocurrencesByTriggerword)</a></h3>
<p>Filters cooccurrences whose sentence contains keywords. Improves precision at the cost of recall.</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.relations.FilterCoocurrencesByTriggerword
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.relations.FilterCoocurrencesIfTooManyEntities">FilterCoocurrencesIfTooManyEntities (ch.epfl.bbp.uima.ae.relations.FilterCoocurrencesIfTooManyEntities)</a></h3>
<p>Filters cooccurrences if more than #PARAM_MAXIMUM_ENTITIES occur in a sentence. Improves precision at the cost of recall.  <i> We tested two simple modifications of the sentence-level co-occurrence technique. The first reduces co-occurrence predictions to sentences with a limited number of brain region mentions. By extracting co-occurring pairs from sentences with only two brain region mentions, precision reaches 23.1% and 17.2% recall (f-measure 1⁄4 19.7%). This means that an average sentence with two brain region mentions is reporting a connection in almost one of four cases. By varying this threshold, the f-measure increases until sentences with six or more brain region mentions are included. We observed that some of these larger sentences merely list brain regions involved in the study and not their relationships. <strong>By limiting the threshold at five brain region mentions or less per sentence, co-occurrence provides 18.8% precision and 66.1% recall.</strong></i>(French 2012)</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>maximumEntities</td><td>the maximum number of enclosed annotations (e.g. brain regions) mentions allowed per enclosing scope. If more, delete ALL co-occurrences in the enclosing scope.</td><td>N</td><td>5</td></tr>
<tr><td>annotationClass</td><td>the enclosed annotation</td><td>N</td><td>ch.epfl.bbp.uima.types.BrainRegion</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.relations.FilterCoocurrencesIfTooManyEntities
 maximumEntities: 5
 annotationClass: ch.epfl.bbp.uima.types.BrainRegion
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.relations.FilterCoocurrencesInLongSentences">FilterCoocurrencesInLongSentences (ch.epfl.bbp.uima.ae.relations.FilterCoocurrencesInLongSentences)</a></h3>
<p>Filters Cooccurrences if the enclosing scope (e.g. Sentence length) is larger than #PARAM_MAXIMUM_SCOPE_LENGTH. Here some sentence length statistics from a random sample of ~50k abstract and pdfs: <pre> Full text Min. 1st Qu. Median Mean 3rd Qu. Max. 1.0 22.0  81.0  109.8 158.0  16380.0 Abstracts Min. 1st Qu. Median Mean 3rd Qu. Max. 2.0 96.0 136.0  145.5 185.0  1215.0 </pre></p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>enclosingScope</td><td>the enclosing scope to iterate on and extract co-occurrence from. Defaults to sentences</td><td>N</td><td>de.julielab.jules.types.Sentence</td></tr>
<tr><td>maximumEnclosingScopeLength</td><td>If the enclosing scope is longer than this value, all co-occurrences are filtered out</td><td>N</td><td>1000</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.relations.FilterCoocurrencesInLongSentences
 enclosingScope: de.julielab.jules.types.Sentence
 maximumEnclosingScopeLength: 1000
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.relations.FilterInactiveCooccurrencesAnnotator">FilterInactiveCooccurrencesAnnotator (ch.epfl.bbp.uima.ae.relations.FilterInactiveCooccurrencesAnnotator)</a></h3>
<p>Filters Cooccurrences with Cooccurrence#getHasInteraction() = false</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.relations.FilterInactiveCooccurrencesAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.relations.WriteCoocurrencesToLoadfile">WriteCoocurrencesToLoadfile (ch.epfl.bbp.uima.ae.relations.WriteCoocurrencesToLoadfile)</a></h3>
<p>Extracts cooccurences Format:<br/> `pubmed_id`,`annot_1_id`,`annot_1_start`,`annot_1_end`,` annot_2_id`,` annot_2_start`,`annot_2_end` Import:<br/> <code>cd to {outputFileDir}</code> <code>cd . (if you ran it again...)</code> <code>mysql -uroot --local-infile</code> <code>use {outputFile}</code> <code>LOAD DATA LOCAL INFILE '{outputFile}' INTO TABLE relations FIELDS TERMINATED BY ' ' LINES TERMINATED BY '\n' (`pubmed_id`,`sentence_id`,`region_1_name`,`region_1_start`,`region_1_end`,`region_2_name`,`region_2_start`,`region_2_end`, `snippet`);</code></p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>outputFile</td><td></td><td>Y</td><td></td></tr>
<tr><td>writeSnippets</td><td></td><td>N</td><td>true</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.relations.WriteCoocurrencesToLoadfile
 outputFile: <put value here>
 writeSnippets: true
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.relations.WriteCoocurrencesToLoadfile2">WriteCoocurrencesToLoadfile2 (ch.epfl.bbp.uima.ae.relations.WriteCoocurrencesToLoadfile2)</a></h3>
<p>Extracts Cooccurrences. Snippet on same file. Format varies, but has the general structure: <ul> <li>pmId</li> <li>confidence</li> <li>e1_id</li> <li>e1_start</li> <li>e1_end</li> <li>(e1_type)</li> <li>e2_id</li> <li>e2_start</li> <li>e2_end</li> <li>(e2_type)</li> <li>snippet_begin (= enclosing scope begin)</li> <li>snippet_end (= enclosing scope end)</li> <li>(snippet)</li> </ul> Output can be loaded into a db, e.g.:<br/> <code>cd to {outputFileDir}</code> <code>cd . (if you ran it again...)</code> <code>mysql -uroot --local-infile</code> <code>use {outputFile}</code> <code>LOAD DATA LOCAL INFILE '{outputFile}' INTO TABLE relations FIELDS TERMINATED BY ' ' LINES TERMINATED BY '\n' (`list`,`of`,`your`,`fields`, ...);</code></p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>outputFile</td><td></td><td>Y</td><td></td></tr>
<tr><td>annot1Type</td><td>an optional id (String, int, whatever) to identify the type of the first annotation.</td><td>N</td><td>NULL</td></tr>
<tr><td>annot2Type</td><td>an optional id (String, int, whatever) to identify the type of the second annotation.</td><td>N</td><td>NULL</td></tr>
<tr><td>cooccurrenceType</td><td>Whether to filter on a given type of cooccurrence. If none provided, selects ALL cooccurrences.</td><td>N</td><td></td></tr>
<tr><td>verbose</td><td>Whether to write the snippet text.</td><td>N</td><td>true</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.relations.WriteCoocurrencesToLoadfile2
 outputFile: <put value here>
 annot1Type: NULL
 annot2Type: NULL
 cooccurrenceType: <put value here>
 verbose: true
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.relations.WriteCoocurrencesToLoadfile3">WriteCoocurrencesToLoadfile3 (ch.epfl.bbp.uima.ae.relations.WriteCoocurrencesToLoadfile3)</a></h3>
<p>Extracts Cooccurrences for projects/extract_brainregions/20140221_slurm_extraction  Format: <pre> pmid, confidence, br1, br1_id, br1_start, br1_end, br2, br2_id, br2_start, br2_end, system1_topdown, system2_kernel, system3_rules, sentence_beg, sentence_end, snippet </pre></p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>outputFile</td><td></td><td>Y</td><td></td></tr>
<tr><td>verbose</td><td>Whether to write the snippet text.</td><td>N</td><td>true</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.relations.WriteCoocurrencesToLoadfile3
 outputFile: <put value here>
 verbose: true
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.serialization.BinaryCasReader">BinaryCasReader (ch.epfl.bbp.uima.ae.serialization.BinaryCasReader)</a></h3>
<p>Reads CASes from a serialized, compressed binary format, in a StructuredDirectory, that has been created with BinaryCasWriter.<br?> REM: it is recommended to specify LargeDirectoryIterator as BlueUima#PARAM_DIRECTORY_ITERATOR, e.g. <code> directoryIterator: LargeDirectoryIterator</code></p>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.ae.serialization.BinaryCasReader
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.serialization.BinaryCasWriter">BinaryCasWriter (ch.epfl.bbp.uima.ae.serialization.BinaryCasWriter)</a></h3>
<p>Writes CASes into a serialized, compressed binary format, using a StructuredDirectory. Can be consumed with RangeBinaryCasReader.</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>outputDir</td><td></td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.ae.serialization.BinaryCasWriter
 outputDir: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.ae.serialization.RangeBinaryCasReader">RangeBinaryCasReader (ch.epfl.bbp.uima.ae.serialization.RangeBinaryCasReader)</a></h3>
<p>Reads CASes from a serialized, compressed binary format, in a StructuredDirectory, that has been created with BinaryCasWriter. Document range defined with upper and lower pmid bounds (PARAM_BETWEEN).</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>inputDirectory</td><td>path to a StructuredDirectory containing serialized CASes</td><td>Y</td><td></td></tr>
<tr><td>between</td><td>specifies a range of pubmed_id, e.g. {13,17} --> 13 <= pubmed_id <= 17</td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.ae.serialization.RangeBinaryCasReader
 inputDirectory: <put value here>
 between: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.annotationviewer.BlueAnnotationViewerAnnotator">BlueAnnotationViewerAnnotator (ch.epfl.bbp.uima.annotationviewer.BlueAnnotationViewerAnnotator)</a></h3>
<p>Creates an html view of the annotations in the CASes.</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>outputDir</td><td></td><td>Y</td><td>annotationViewer/</td></tr>
<tr><td>styleMap</td><td></td><td>Y</td><td>viewer/blueStyleMap.xml</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.annotationviewer.BlueAnnotationViewerAnnotator
 outputDir: annotationViewer/
 styleMap: viewer/blueStyleMap.xml
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.cr.AbstractFileReader">AbstractFileReader (ch.epfl.bbp.uima.cr.AbstractFileReader)</a></h3>
<p></p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>inputDirectory</td><td>path to a directory containing pdfs, or path to a zip file containing pdfs (make sure it does not contain other file formats)</td><td>Y</td><td></td></tr>
<tr><td>directoryIterator</td><td>the directoryIterator to use. E.g. DefaultDirectoryIterator, ZipDirectoryIterator, LargeDirectoryIterator</td><td>Y</td><td>DefaultDirectoryIterator</td></tr>
<tr><td>isRecursive</td><td></td><td>Y</td><td>false</td></tr>
<tr><td>fileExtensionFilter</td><td>a filter on file extension</td><td>Y</td><td>null</td></tr>
</table>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.cr.AbstractFileReader
 inputDirectory: <put value here>
 directoryIterator: DefaultDirectoryIterator
 isRecursive: false
 fileExtensionFilter: null
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.cr.ConcatReader">ConcatReader (ch.epfl.bbp.uima.cr.ConcatReader)</a></h3>
<p>TODO</p>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.cr.ConcatReader
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.cr.FileReader">FileReader (ch.epfl.bbp.uima.cr.FileReader)</a></h3>
<p>Simply iterates a directory, and delegates to an AnalysisEngine to retrieve the actual file and process it. NOTE: no JCas.documentText is set yet, the first AnalysisEngine must do that</p>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.cr.FileReader
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.cr.FromFilelistReader">FromFilelistReader (ch.epfl.bbp.uima.cr.FromFilelistReader)</a></h3>
<p>Simply iterates a file list (provided as txt file), and delegates to an AnalysisEngine to retrieve the actual file and process it. NOTE: NO JCas.documentText is set yet, the first AnalysisEngine must do that</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>inputFile</td><td>path to a txt file containing a list of file paths, one on each line. Each line is on the format {doc_id}	{path}</td><td>Y</td><td></td></tr>
<tr><td>pathPrefix</td><td>prefix (=root path) to all files, leave it out for no prefix</td><td>N</td><td></td></tr>
<tr><td>format</td><td>if true, then format is just the path, and the file name is the pubmed id</td><td>N</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.cr.FromFilelistReader
 inputFile: <put value here>
 pathPrefix: <put value here>
 format: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.cr.LdaCReader">LdaCReader (ch.epfl.bbp.uima.cr.LdaCReader)</a></h3>
<p>Reads a corpus in LDA-C format: <code> [M] [term_1]:[count] [term_2]:[count] ... [term_N]:[count]</code> where [M] is the number of unique terms in the document, and the [count] associated with each term is how many times that term appeared in the document.</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>inputDirectory</td><td>path to a directory containing pdfs, or path to a zip file containing pdfs (make sure it does not contain other file formats)</td><td>Y</td><td></td></tr>
<tr><td>directoryIterator</td><td>the directoryIterator to use. E.g. DefaultDirectoryIterator, ZipDirectoryIterator, LargeDirectoryIterator</td><td>Y</td><td>DefaultDirectoryIterator</td></tr>
<tr><td>isRecursive</td><td></td><td>Y</td><td>false</td></tr>
<tr><td>fileExtensionFilter</td><td>a filter on file extension</td><td>Y</td><td>null</td></tr>
</table>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.cr.LdaCReader
 inputDirectory: <put value here>
 directoryIterator: DefaultDirectoryIterator
 isRecursive: false
 fileExtensionFilter: null
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.cr.OneDocPerLineIdsReader">OneDocPerLineIdsReader (ch.epfl.bbp.uima.cr.OneDocPerLineIdsReader)</a></h3>
<p>CollectionReader that takes simple text files as input. Each line is turned into a new CAS. Format is: <code>{docId}{id_word1}{id_word2}{id_word3}</code></p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>inputFile</td><td>path to the corpus file</td><td>Y</td><td></td></tr>
<tr><td>vocabularyInputFile</td><td></td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.cr.OneDocPerLineIdsReader
 inputFile: <put value here>
 vocabularyInputFile: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.cr.OneDocPerLineReader">OneDocPerLineReader (ch.epfl.bbp.uima.cr.OneDocPerLineReader)</a></h3>
<p>CollectionReader that takes a simple text file as input. Each line is turned into a new CAS. Format is: <code>docId{tab}text</code> If not tab is found (= no docId is given), then the document text is the whole line, and an incremental docId is generated.<br/> Lines starting with '#' are ignored. @see SentenceDumpAnnotator</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>inputFile</td><td>path to text file</td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.cr.OneDocPerLineReader
 inputFile: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.cr.OneDocPerLineReader2">OneDocPerLineReader2 (ch.epfl.bbp.uima.cr.OneDocPerLineReader2)</a></h3>
<p>CollectionReader that takes a simple text file as input. Each line is turned into a new CAS. Format is: <code>docId{tab}"title"{tab}"abstract"</code> Lines starting with '#' are ignored.</p>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.cr.OneDocPerLineReader2
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.cr.OneDocPerLineReader3">OneDocPerLineReader3 (ch.epfl.bbp.uima.cr.OneDocPerLineReader3)</a></h3>
<p>CollectionReader that takes simple text files as input. Each file is turned into a new CAS. Format is: <code>docId{tab}text</code></p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>inputDirectory</td><td>path to directory</td><td>Y</td><td></td></tr>
<tr><td>between</td><td>specifies a range of pubmed_id, e.g. {13,17} --> 13 <= pubmed_id <= 17. It is recommended to keep it under 1M, as these results are all stored in the db memory</td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.cr.OneDocPerLineReader3
 inputDirectory: <put value here>
 between: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.cr.SingleAbstractReader">SingleAbstractReader (ch.epfl.bbp.uima.cr.SingleAbstractReader)</a></h3>
<p>Reads a single sample abstract, pmId 1957687. Useful for testing.</p>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.cr.SingleAbstractReader
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.cr.SingleFileReader">SingleFileReader (ch.epfl.bbp.uima.cr.SingleFileReader)</a></h3>
<p>Simply reads a single file, and delegates to an AnalysisEngine to retrieve the actual file and process it. NOTE: no JCas.documentText is set yet, the first AnalysisEngine must do that</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>inputFile</td><td>path to file</td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.cr.SingleFileReader
 inputFile: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.cr.TextArrayReader">TextArrayReader (ch.epfl.bbp.uima.cr.TextArrayReader)</a></h3>
<p>CollectionReader that takes a simple text array as input.</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>input</td><td>a array of string, to be processed</td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.cr.TextArrayReader
 input: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.cr.TextFileReader">TextFileReader (ch.epfl.bbp.uima.cr.TextFileReader)</a></h3>
<p>Iterates the given directory, and parses the text of individual .txt files into JCases.</p>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.cr.TextFileReader
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.cr.TextLineReader">TextLineReader (ch.epfl.bbp.uima.cr.TextLineReader)</a></h3>
<p>CollectionReader that takes a simple text file as input. Each line is turned into a new CAS. Alternatively, each new empty lines creates a new CAS (using the TextLineReader#PARAM_SPLIT_MODE parameter).</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>inputFile</td><td>path to text file</td><td>Y</td><td>pear_resources/sample_file.txt</td></tr>
<tr><td>splitMode</td><td>how to split for new CAS. Values are 1 (split on each new line, default), 2 (split on empty new line)</td><td>Y</td><td>1</td></tr>
</table>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.cr.TextLineReader
 inputFile: pear_resources/sample_file.txt
 splitMode: 1
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.cr.TextReader">TextReader (ch.epfl.bbp.uima.cr.TextReader)</a></h3>
<p>CollectionReader that takes a simple text as input. Produces a single JCas. Useful for testing.</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>input</td><td>a string, to be processed</td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.cr.TextReader
 input: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.cr.XCollectionReader">XCollectionReader (ch.epfl.bbp.uima.cr.XCollectionReader)</a></h3>
<p>A simple collection reader that reads CASes in as XMIs from a directory in the filesystem.</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>xmlSchemeName</td><td>specifies the UIMA XML serialization scheme that should be used. Valid values for this parameter are 'XMI' and 'XCAS'</td><td>Y</td><td>XMI</td></tr>
</table>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.cr.XCollectionReader
 xmlSchemeName: XMI
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.cr.ZipXmiCollectionReader">ZipXmiCollectionReader (ch.epfl.bbp.uima.cr.ZipXmiCollectionReader)</a></h3>
<p>A simple collection reader that reads CASes in as Zipped XMIs from a directory in the filesystem.</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>xmlSchemeName</td><td>specifies the UIMA XML serialization scheme that should be used. Valid values for this parameter are 'XMI' and 'XCAS'</td><td>Y</td><td>XMI</td></tr>
</table>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.cr.ZipXmiCollectionReader
 xmlSchemeName: XMI
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.filter.AnnotationFilterAnnotator">AnnotationFilterAnnotator (ch.epfl.bbp.uima.filter.AnnotationFilterAnnotator)</a></h3>
<p>Filters Keeps that enclose the configured Annotations.</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>annotationClasses</td><td>an array with the full name of each annotation classes</td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.filter.AnnotationFilterAnnotator
 annotationClasses: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.filter.EtAlAnnotator">EtAlAnnotator (ch.epfl.bbp.uima.filter.EtAlAnnotator)</a></h3>
<p>Text-level filtering. Finds occurences of et al.</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.filter.EtAlAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.filter.FrequencyFilterAnnotator">FrequencyFilterAnnotator (ch.epfl.bbp.uima.filter.FrequencyFilterAnnotator)</a></h3>
<p>Removes Keep annotations that are too frequent or not frequent enough (aka "hapax"), based on a frequency list (that has been generated with FrequencyFilterWriter.</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>minimumFrequency</td><td>minimum frequency of token to be retained</td><td>Y</td><td></td></tr>
<tr><td>maximumFrequency</td><td>maximum frequency of token to be retained</td><td>Y</td><td>2147483647</td></tr>
<tr><td>caseSensitive</td><td>If true, tokens are not normalized to lowercase before string comparisions</td><td>Y</td><td>false</td></tr>
<tr><td>inputFile</td><td>Path to file containing tokens and their frequency in the corpus</td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.filter.FrequencyFilterAnnotator
 minimumFrequency: <put value here>
 maximumFrequency: 2147483647
 caseSensitive: false
 inputFile: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.filter.FrequencyFilterWriter">FrequencyFilterWriter (ch.epfl.bbp.uima.filter.FrequencyFilterWriter)</a></h3>
<p>Generates a frequency list, based on Keep#getNormalizedText(), and on whether to filter the whole document with BlueCasUtil#keepDoc(JCas). This frequency list can be used with FrequencyFilterAnnotator. sort it with sort -t $'\t' -k 2nr vocab_file</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>caseSensitive</td><td>If true, tokens are not normalized to lowercase before string comparisions</td><td>Y</td><td>false</td></tr>
<tr><td>outputFile</td><td>Where to write frequency file</td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.filter.FrequencyFilterWriter
 caseSensitive: false
 outputFile: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.filter.KeepsCleaner">KeepsCleaner (ch.epfl.bbp.uima.filter.KeepsCleaner)</a></h3>
<p>Performs cleaning on Keep#getNormalizedText(). Should be performed at the end of the filtering process. Detailed steps: <br/> Remove Keep if normalizedText length < minLength or does not contain balanced parenthesis (e.g. "(hello") or text starts with 'www.' or text consist only of punctuation and numbers.<br/> Then optionally lowercase and finally removes punctuation if it starts or ends with punctuation.</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>transformLowercase</td><td>Whether to transform lowercase all the Keep's getNormalizedText()</td><td>N</td><td>true</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.filter.KeepsCleaner
 transformLowercase: true
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.filter.KeepsDumper">KeepsDumper (ch.epfl.bbp.uima.filter.KeepsDumper)</a></h3>
<p>Dumps all Keeps to sysout, useful for debugging</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>printCoveredText</td><td>Prints the covered text of every Keep</td><td>Y</td><td>false</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.filter.KeepsDumper
 printCoveredText: false
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.filter.KeepsWriter">KeepsWriter (ch.epfl.bbp.uima.filter.KeepsWriter)</a></h3>
<p>Writes all Keeps to a file. One document per line. Useful to train word2vec</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>outputFile</td><td></td><td>Y</td><td></td></tr>
<tr><td>writeDashes</td><td>Whether to replace all spaces in (multi)words with dashes ('_')</td><td>N</td><td>false</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.filter.KeepsWriter
 outputFile: <put value here>
 writeDashes: false
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.filter.LeaveOnlyKeepsEnclosedAnnotationsAnnotator">LeaveOnlyKeepsEnclosedAnnotationsAnnotator (ch.epfl.bbp.uima.filter.LeaveOnlyKeepsEnclosedAnnotationsAnnotator)</a></h3>
<p>Remove ALL Annotations, except the ones referenced by Keep annotations. Useful as a global cleanup after the filtering step, e.g. to display annotations in BartWriter</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.filter.LeaveOnlyKeepsEnclosedAnnotationsAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.filter.MeasureNormalizerAnnotator">MeasureNormalizerAnnotator (ch.epfl.bbp.uima.filter.MeasureNormalizerAnnotator)</a></h3>
<p>Normalizes Keep#getNormalizedText() that cover a Measure by removing the numeric part and leaving only the unit. E.g. "28 mM" becomes "MEASURE_mM". Useful e.g. for LDA, when the numeric part is irrelevant/confusing, but the unit is.</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>removeSimpleMeasure</td><td>Remove measures which are single numbers (MEASURE_)</td><td>Y</td><td>false</td></tr>
<tr><td>removeDateMeasure</td><td>Remove measures which are single numbers (MEASURE_Date)</td><td>Y</td><td>false</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.filter.MeasureNormalizerAnnotator
 removeSimpleMeasure: false
 removeDateMeasure: false
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.filter.PunctuationFilterAnnotator">PunctuationFilterAnnotator (ch.epfl.bbp.uima.filter.PunctuationFilterAnnotator)</a></h3>
<p>Removes Keep annotations whose Keep#getNormalizedText() is a punctuation. @see PunctuationAnnotator PunctuationAnnotator for the list</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.filter.PunctuationFilterAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.filter.ReferencesFinderAnnotator">ReferencesFinderAnnotator (ch.epfl.bbp.uima.filter.ReferencesFinderAnnotator)</a></h3>
<p>Creates (at most) one Section annotation if a "References" section-title is found. Uses a simple regex.</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.filter.ReferencesFinderAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.filter.SectionAnnotator">SectionAnnotator (ch.epfl.bbp.uima.filter.SectionAnnotator)</a></h3>
<p>/ Annotates DocumentBlocks with ContentSection like Acknowlegments, Correspondance, etc. Uses lists of section titles.<br/> Lists developped by analyzing a large document sample, with focus on high-precision (at the cost of recall).</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.filter.SectionAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.filter.SectionFilterAnnotator">SectionFilterAnnotator (ch.epfl.bbp.uima.filter.SectionFilterAnnotator)</a></h3>
<p>Removes Keep annotations that are located into a DocumentBlock whose ContentSection is non-content, e.g. bibliography, acknowledgment, ...</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.filter.SectionFilterAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.filter.SectionRegexAnnotator">SectionRegexAnnotator (ch.epfl.bbp.uima.filter.SectionRegexAnnotator)</a></h3>
<p>Annotates DocumentBlocks with ContentSection like Acknowlegments, Correspondance, etc. Uses regexes.<br/> Patterns developped by analyzing a large document sample, with focus on high-precision (at the cost of recall).</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.filter.SectionRegexAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.filter.SentenceFilterAnnotator">SentenceFilterAnnotator (ch.epfl.bbp.uima.filter.SentenceFilterAnnotator)</a></h3>
<p>Remove sentences that do not contain a given regex</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>outputDir</td><td></td><td>Y</td><td>target/</td></tr>
<tr><td>regex</td><td>Regex that should find() in the desired sentences</td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.filter.SentenceFilterAnnotator
 outputDir: target/
 regex: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.filter.SimpleNormalizerAnnotator">SimpleNormalizerAnnotator (ch.epfl.bbp.uima.filter.SimpleNormalizerAnnotator)</a></h3>
<p>Lemmatizes every Keep annotation and sets its Keep#setNormalizedText(), by (just) trimming the annotation's text.</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>caseSensitive</td><td>If true, tokens are not normalized to lowercase before string comparisions</td><td>Y</td><td>false</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.filter.SimpleNormalizerAnnotator
 caseSensitive: false
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.filter.SnowballStemmerNormalizerAnnotator">SnowballStemmerNormalizerAnnotator (ch.epfl.bbp.uima.filter.SnowballStemmerNormalizerAnnotator)</a></h3>
<p>Stems every Keep annotation and sets its Keep#setNormalizedText(), using Snowball/Porter's algorithm.</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>caseSensitive</td><td>If true, tokens are not normalized to lowercase before string comparisions</td><td>Y</td><td>false</td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.filter.SnowballStemmerNormalizerAnnotator
 caseSensitive: false
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.filter.StopwordFilterAnnotator">StopwordFilterAnnotator (ch.epfl.bbp.uima.filter.StopwordFilterAnnotator)</a></h3>
<p>Removes Keep annotations whose Keep#getNormalizedText() belongs to a stopword list. Stoplist format: one word per line.</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>caseSensitive</td><td>If true, tokens are not normalized to lowercase before string comparisions</td><td>Y</td><td>false</td></tr>
<tr><td>inputFile</td><td>path to the stopword list. If none is provided, the stopword list of Mallet is used</td><td>N</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.filter.StopwordFilterAnnotator
 caseSensitive: false
 inputFile: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.filter.Tokens2KeepAnnotator">Tokens2KeepAnnotator (ch.epfl.bbp.uima.filter.Tokens2KeepAnnotator)</a></h3>
<p>Add a Keep for every Token. Useful when testing the filtering steps, without using ViterbiFilterAnnotator.</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.filter.Tokens2KeepAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.filter.TooFewTokensFilterAnnotator">TooFewTokensFilterAnnotator (ch.epfl.bbp.uima.filter.TooFewTokensFilterAnnotator)</a></h3>
<p>Document-level filtering.Flags a document that has too few tokens per page (< 50 on average).</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.filter.TooFewTokensFilterAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.filter.TooMuchOOVFilterAnnotator">TooMuchOOVFilterAnnotator (ch.epfl.bbp.uima.filter.TooMuchOOVFilterAnnotator)</a></h3>
<p>Document-level filtering. Flags a document that has too much OOV tokens, compared to a frequency list. Some basic whitelisting is performed (Uppercase-then-lowercases or 2x-more-digits-than-letters).</p>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.filter.TooMuchOOVFilterAnnotator
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.validation.CrossvalidationReader">CrossvalidationReader (ch.epfl.bbp.uima.validation.CrossvalidationReader)</a></h3>
<p>Wraps any CollectionReader to perform cross validation.</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>corpusName</td><td></td><td>Y</td><td></td></tr>
<tr><td>maxNrResults</td><td></td><td>Y</td><td></td></tr>
<tr><td>seed</td><td></td><td>Y</td><td>17</td></tr>
<tr><td>splits</td><td></td><td>Y</td><td>10</td></tr>
<tr><td>slice</td><td>which slice of the above split</td><td>Y</td><td></td></tr>
<tr><td>modeEval</td><td>true => eval (=returns 1 slice for eval); false => train (=returns e.g. 9 slices for training)  </td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>cr: ch.epfl.bbp.uima.validation.CrossvalidationReader
 corpusName: <put value here>
 maxNrResults: <put value here>
 seed: 17
 splits: 10
 slice: <put value here>
 modeEval: <put value here>
</pre>
<br/>
<h3><a id="ch.epfl.bbp.uima.validation.CrossvalidationWriter">CrossvalidationWriter (ch.epfl.bbp.uima.validation.CrossvalidationWriter)</a></h3>
<p>Used after the CollectionReader of an annotated corpus to persist it for subsequent use (cross validation). See CrossvalidationReader</p>
<table><thead><td>Param. Name</td><td>Description</td><td>Required</td><td>Default Value</td></thead>
<tr><td>corpusName</td><td></td><td>Y</td><td></td></tr>
</table>
<p>Usage (example):</p><pre>ae: ch.epfl.bbp.uima.validation.CrossvalidationWriter
 corpusName: <put value here>
</pre>
<br/>
</body></html>
